---
title: "November"  
---

November was a month of momentum across customers, models, governance, and community.

Teams like Snorkel AI continue to push the boundaries of evaluation and training pipelines, running multi-agent systems that compare and verify outputs across models like Anthropic and Gemini. We‚Äôve been learning a lot from how organizations like these operate at scale.

On the platform side, we expanded our provider landscape, shipped multiple model releases on Day 0, and worked on enhancing our guardrails and observability.

We‚Äôre closing the year with conversations and gatherings across the community! If you‚Äôre attending <b>AWS re:Invent</b> and want to meet the core team behind Portkey, grab a 1:1 slot [here](https://calendly.com/d/csjy-mr6-vfg/aws-re-invent).


## Summary

| Area | Key Highlights |
|---|---|
| **Models & Providers** | ‚Ä¢ GPT-5.1 <br />‚Ä¢ Gemini 3.0<br />‚Ä¢ Claude Opus 4.5 <br />‚Ä¢ New providers: Z-AI, MatterAI, CometAPI, Modal Labs |
| **Platform** | ‚Ä¢ Conditioner Router now supports URL-based conditions<br />‚Ä¢ Usage limits & rate-limit policies for org-wide control |
| **Observability** | ‚Ä¢ Trace visibility by category<br />‚Ä¢ Guardrail checks highlighted in logs<br />‚Ä¢ OTEL log export |
| **Guardrails** | ‚Ä¢ F5 Guardrail added<br />‚Ä¢ Javelin Guardrails added <br /> ‚Ä¢ Guardrails for streaming responses|

## How Snorkel AI runs multi-agents evals for frontier models

Snorkel AI has been doing some fascinating work around evaluating frontier models from Anthropic, Google, and others. Their team built a multi-agent evaluation system that plans, reasons, and verifies model outputs.

As the scale and complexity of these eval workloads increased, they needed a way to move beyond fragmented scripts and logs toward a single, reliable source of truth for debugging.

Read their [full breakdown](https://portkey.ai/blog/how-snorkel-evaluates-and-trains-top-ai-models) that includes architecture, evaluation flows, learnings, and infrastructure decisions.

<img src="/images/changelog/snorkel-multi-agent-systems.png" alt="industry-leader-testimonial" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

## Platform

### Budget policies

You can now define usage budgets and throughput controls at an organization or team level, without configuring them individually using budget policies.
You can create usage limits and rate limit policies with conditions based on:

- API keys
- Metadata fields
- Workspaces
- Combined multi-condition rules

This makes governance far more scalable. See how you can set up usage limits and rate-limit policies [here](https://portkey.ai/docs/product/enterprise-offering/budget-policies).

### URL support in Conditional Router 

You can match requests based on the request's URL path, increases the for routing and giving you granular control over model selection. Read more about this [here](https://portkey.ai/docs/product/ai-gateway/conditional-routing#url-path-routing).
<img src="/images/changelog/url-path.png" alt="url-path-conditional-router" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

## From the who's who in the industry!
<img src="/images/changelog/industry-leader-testimonial.png" alt="industry-leader-testimonial" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

## Observability

### Improved trace visibility

You can now see traces by category, making it easier to understand whether traffic originated from chat, batch, routing, agent calls, or system functions.

<img src="/images/changelog/traces-category.png" alt="trace-category" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

### Detailed guardrail checks in logs

See guardrail-flagged events more prominently in logs, simplifying debugging of blocked, redacted, or policy-violating requests.

<img src="/images/changelog/guardrails-logs.png" alt="guardrails-checks-in-logs" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

### OTEL Log Export [Experimental]

You can now export Gateway logs to an OpenTelemetry-compatible endpoint, aligned to experimental GenAI semantic conventions, allowing external systems to ingest AI activity traces. Read more about this [here](https://portkey.ai/docs/product/observability/opentelemetry#experimental-features).

## Guardrails

### F5 Guardrail

You can now configure **F5 Guardrails**, expanding Portkey‚Äôs guardrails ecosystem for runtime moderation, safety filtering, and structured response control. 

This enables additional security layers for production workloads and is especially useful when running automated agent pipelines or public-facing interfaces. See how you can implement F5 Guardrails [here](https://portkey.ai/docs/integrations/guardrails/f5-guardrails).

### Qualifire Guardrails

Qualifire offers a comprehensive suite of **AI safety and quality guardrails** designed to keep applications compliant, safe, and high-integrity in production. 

Their platform provides **20+ guardrail checks** spanning content risk, output validation, and policy compliance. See how you can implement Qualifire Guardrails [here](https://portkey.ai/docs/integrations/guardrails/qualifire).

### Guardrails in streaming responses

Streaming endpoints (`/chat/completions`, `/completions`, `/embeddings`, `/messages`) can now return guardrail evaluation results in real time.

This helps you to:

- Stop streaming mid-response
- Mask or redact content dynamically
- Enforce content policy on UI without waiting for the full generation

## Customer Love!
<img src="/images/changelog/snorkel-testimonial.png" alt="snorkel-testimonial" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />


## Gateway

### New models & providers

<div style={{ display: "flex", gap: "2rem", flexWrap: "wrap" }}>
  <div style={{ flex: 1, minWidth: 300 }}>
    <ul>
      <li><b>GPT-5.1</b>: Frontier-grade model now available.</li>
      <li><b>Gemini 3.0</b>: Google‚Äôs latest model with improved reasoning performance.</li>
      <li><b>Claude Opus 4.5</b>: Anthropic‚Äôs strongest reasoning model.</li>
    </ul>
  </div>

  <div style={{ flex: 1, minWidth: 300 }}>
    <ul>
      <li><b>MatterAI</b>: Reasoning-focused LLM provider with models Axon, Axon Mini, Axon Code.</li>
      <li><b>Z-AI</b>: Multiple model families with flexible deployment for experimentation, inference, and evaluation</li>
      <li><b>CometAPI</b>: Enabling high-concurrency access to hundreds of models through a single endpoint.</li>
      <li><b>Modal Labs</b>: A high-performance serverless platform for model hosting and inference execution.</li>
    </ul>
  </div>
</div>

### Model & Provider Enhancements

<ul>
  <li>Vertex AI: Added support for Computer Use and `anthropic-beta`</li>
  <li>OpenAI: Added support for `conversation` & `modalities` parameters and pricing for Sora models.</li>
  <li>Azure OpenAI: Added support for `model-router`and pricing for Sora models. </li>
  <li>Azure Foundry: Added support for Anthropic models</li>
  <li>Pricing for gemini-2.5-flash-image, gemini-3-pro-image-preview, Veo and Together AI's image models</li>
  <li>Pricing for fine-tuning operations across OpenAI, Azure OpenAI, and Vertex AI</li>
</ul>


## Community & Events

### Meet us in person at AWS re:Invent!

We‚Äôre at **AWS re:Invent**! If you'd like to meet the founders, discuss platform strategy, or just meet for ‚òïÔ∏è ,grab a 1:1 slot [here](https://calendly.com/d/csjy-mr6-vfg/aws-re-invent).

### 3000 Tokens/Sec - Building a high throughput LLM inference engine

We're hosting a joint session with **Cerebras** on running high-throughput inference
(~3,000 tokens/sec+) in production.

üìÖ 9th December: Join us [live](https://luma.com/dzzf3iq8)

### Private Dinner with AI & Tech Leaders (San Francisco)

We're hosting a **private dinner in San Francisco on 8th December, Monday** for AI infra
leaders, CTOs, and platform engineers. Expect deep product conversations, real scaling stories, and strong networking energy.

Seats are limited, [request an invite](https://luma.com/pa4azaix).

### Private Dinner for Higher Education and Research (Denver)

We're also hosting a closed-room **education-focused leadership dinner at Denver
on 10th December, Wednesday**. We'll be discussing the unique challenges of adopting AI in research and higher-ed settings, including compliance, data privacy, and infrastructure needs.

üéì Ideal for CIOs and higher-ed AI program leads. [Request an invite](https://luma.com/2efn9ias)


## Resources
* **Blog**: [From standard to ecosystem: the new MCP updates](https://portkey.ai/blog/new-mcp-updates)
* **Blog**: [AI tool sprawl: causes, risks, and how teams can regain control](https://portkey.ai/blog/ai-tool-sprawl-causes-risks-and-how-teams-can-regain-control)
* **Blog**: [The complete guide to LLM observability for 2026](https://portkey.ai/blog/the-complete-guide-to-llm-observability)
* **Blog**: [AI cost observability: A practical guide to understanding and managing LLM spend](https://portkey.ai/blog/ai-cost-observability-a-practical-guide-to-understanding-and-managing-llm-spend)

## Community Contributors
A special thanks to our contributors this month:[jroberts2600](https://github.com/jroberts2600) and [drorIvry](https://github.com/drorIvry).

## Support

<CardGroup cols={2}>
<Card title="Need Help?" icon="bug" href="https://github.com/Portkey-AI/gateway/issues">
Open an issue on GitHub
</Card>
<Card title="Join Us" icon="discord" href="https://portkey.wiki/community">
Get support in our Discord
</Card>
</CardGroup>