---
title: "October"  
---

Portkey has been recognized as one of the 2025 Gartner® Cool Vendors™ in LLM Observability, highlighting our work in bringing visibility, reliability, and governance to production AI systems.

Alongside this recognition, we shipped major platform updates including Terraform support, enhanced rate limiting and timeout controls, new security guardrails, and improved observability.

We’re also preparing for a series of upcoming conversations and community sessions focused on building and governing AI responsibly in production.

And as always, we continue to learn from how our customers use Portkey, helping us refine the platform for production AI everywhere.

## Summary

| Area | Key Highlights |  
| :----------- | :------------------------------------------------------------------------------------------------------------------------------------------- |  
| **Platform** | • Terraform Provider for Portkey <br /> • Configurable request timeouts <br /> • Enhanced rate limits for tokens and requests |  
| **Agents** | • OpenAI AgentKit with multi-provider support |  
| **Guardrails** | • Javelin AI Security integration <br /> • Add Prefix guardrail <br /> • Allowed Request Types guardrail |  
| **Gateway & Providers** | • Claude Haiku 4.5 <br /> • Expanded provider updates (OpenAI, Azure, Bedrock, Vertex AI) |  
| **Observability** | • Structured tool-call visibility <br /> • Enhanced web search view for Anthropic |  
---
## Portkey recognized as a 2025 Gartner® Cool Vendor™ in LLM Observability

<img src="/images/changelog/Gartner Cool Vendor.png" alt="2025 Gartner® Cool Vendor™" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

Portkey has been recognized as one of the [2025 Gartner® Cool Vendors™ in LLM Observability](https://www.gartner.com/en/documents/7024598), in the report by Padraig Byrne, Tanmay Bisht, and Andre Bridges. This recognition reinforces our mission to help teams move from experimentation to production with confidence and observability built in.

If you like what we are building, please drop us a review <a href="https://www.gartner.com/reviews/observability-platforms/form?vid=91488&pid=172430">here</a>, it'd mean a lot to us!

## What industry leaders are telling about us!
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761814339354_Group%201000006848_01K8T52RDNGAZ3JF69K83B1J3E.png" alt="anthropic" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

## Platform

### Terraform Provider for Portkey

Portkey now has a Terraform provider for managing workspaces, users, and organization resources through the Portkey Admin API. This enables you to manage:

- Workspaces: Create and update workspaces for teams and projects
- Members: Assign users to workspaces with defined roles
- Access: Send user invites with organization and workspace access
- Users: Query and manage existing users in your organization

### Enhanced rate limits

You can now configure rate limits for both requests and tokens under each API key, giving teams precise control over workload, costs, and performance across large deployments.
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761814820388_Group%201000006842_01K8T5HE79ZPC06H4ZGC2FQ305.png" alt="Enhanced rate limits" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

- Request-based limits: Cap the number of requests per minute, hour, or day.
- Token-based limits: Cap the number of tokens consumed per minute, hour, or day.

### Configurable request timeouts

A new `REQUEST_TIMEOUT` environment variable lets you control how long the Gateway waits before timing out outbound LLM requests — helping fine-tune latency, retries, and reliability for large-scale workloads.

## Customer love!
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761809556631_Group%201000006840_01K8T0GS9XCEQF2QQJQQTX2S15.png" alt="Enhanced rate limits" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />


## Guardrails

### Javelin AI Security integration

You can now configure Javelin AI Security guardrails directly in the Portkey Gateway to evaluate every model interaction for:

- Trust & Safety — detect and filter harmful or unsafe content
- Prompt Injection Detection — identify attempts to manipulate model behavior
- Language Detection — verify and filter language in user or model responses

These guardrails extend Portkey’s security layer, making it easier to enforce safe and compliant model use at scale. See how to set up Javelin guardrails [here](https://portkey.ai/docs/integrations/guardrails/javelin).

### Add Prefix guardrail

<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761814825590_Group%201000006845_01K8T5HJRK7Z11JGACH2X2PT19.png" alt="Add Prefix guardrail" style={{maxWidth: "60%", borderRadius: "8px", margin: "24px 0"}} />

The new Add Prefix guardrail lets you automatically prepend a configurable prefix to user inputs before sending them to the model, useful for enforcing consistent tone, context, or compliance instructions across all model interactions.

### Allowed Request Types guardrail
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761814823269_Group%201000006844_01K8T5HGFXV3ME9ZC9HX13BC6K.png" alt="Allowed Request Types guardrail" style={{maxWidth: "60%", borderRadius: "8px", margin: "24px 0"}} />

With the Allowed Request Types guardrail, you can now define which request types (endpoints) are permitted through the Gateway. Use an allowlist or blocklist approach to control access at a granular level and restrict unwanted request types.

## Gateway

### New models and providers

<div style={{ display: "flex", gap: "2rem", flexWrap: "wrap" }}>
  <div style={{ flex: 1, minWidth: 300 }}>
    <ul>
      <li>
        <b>Claude Haiku 4.5</b>: Anthropic’s lightweight model for real-time use cases.
      </li>
      <li>
        <b>OpenAI & Azure OpenAI</b>: Added support for streaming audio transcription.
      </li>
      <li>
        <b>Vertex AI</b>: Added custom-model support for batching and input-audio parameter.
      </li>
    </ul>
  </div>

  <div style={{ flex: 1, minWidth: 300 }}>
    <ul>
      <li>
        <b>AWS Bedrock</b>: Added global profiles, token counting, and batch pass-throughs.
      </li>
      <li>
        <b>Azure</b>: Improved Entra caching and image-editing pricing support.
      </li>
      <li>
        <b>Anthropic Beta (Vertex AI)</b>: Added beta header support for compatibility.
      </li>
    </ul>
  </div>
</div>

## Agents

### OpenAI AgentKit with multi-provider support

Building agents is now easier with OpenAI’s AgentKit, Portkey takes it further. You can now connect your AgentKit agents to 1,600+ LLMs across providers through Portkey, while gaining end-to-end observability, guardrails, and cost tracking. 

See the integration guide [here](https://portkey.ai/docs/integrations/libraries/openai-agent-builder)

## Observability

### Structured tool call visibility
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761820472263_Group%201000006846_01K8TAXXM07SM245133N4XHB23.png" alt="Structured tool call visibility" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

Tool calls made during model interactions are now automatically detected and displayed as **separate, structured entries** in the Portkey logs.  
This makes it easier to trace the tools invoked, inspect parameters, and understand agent behavior across multi-step workflows.

### Enhanced view for web search
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761820475048_Group%201000006847_01K8TAXZSZHFSCY2KKV0G9F9RD.png" alt="Enhanced view for web search" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} />

Web search results from Anthropic models now appear in a **clearer, formatted view** within the dashboard.  
This update improves readability and makes it easy to see what information the model used to generate its response, enabling faster analysis and better transparency.

## Customer Stories: From arm pain to AI gateway
After an unexpected setback forced Rahul Bansal to rethink how he worked, he built Dictation Daddy, an AI-powered dictation platform now used by professionals, doctors, and lawyers to write faster and with greater accuracy, powered by Portkey. 

Read the full story [here](https://portkey.ai/blog/from-arm-pain-to-ai-gateway/)


## Community & Events

### MCP Gateway for Higher Education
<img src="https://userimg-assets.customeriomail.com/images/client-env-144095/1761814120591_Portkey%20Joins%20NET+%20(3)_01K8T4W2SKT3FVS2CD4G4BC2K1.png" alt="MCP Gateway for Higher Education" style={{maxWidth: "60%", borderRadius: "8px", margin: "24px 0"}} />

We’re teaming up with Internet2 to host a session on how higher education institutions can implement the Model Context Protocol (MCP) securely and at scale.

[Join us](https://luma.com/4i4qspq0) to learn how MCP fits within existing campus IT frameworks, what governance models are emerging, and the practical steps universities can take to enable secure, compliant AI access across departments.

### LibreChat in Production

<img src="/images/changelog/Webinar Dark (7).png" alt="Regex Replace Guardrail" style={{maxWidth: "60%", borderRadius: "8px", margin: "24px 0"}} />

LibreChat makes it easy to build chat-based AI experiences but adding governance, access control, and observability is key to running it in production.

<a href="https://luma.com/cywhfpko">Join us </a> to see how Portkey brings budgets, RBAC, and usage visibility to LibreChat, while connecting to 1,600+ LLMs across providers.


## Resources
* **Blog**: [Observability is now a business function for AI](https://portkey.ai/blog/observability-is-now-a-business-function-for-ai)
* **Blog**: [Using OpenAI AgentKit with Anthropic, Gemini and other providers](https://portkey.ai/blog/using-openai-agentkit-with-anthropic-gemini-and-other-providers)
* **Blog**: [What we think of the Opentelemetry semantic conventions for GenAI traces](https://portkey.ai/blog/opentelemetry-semantic-conventions-for-genai-traces)
* **Blog**: [Comparing lean LLMs: GPT-5 Nano and Claude Haiku 4.5](https://portkey.ai/blog/gpt-5-nano-vs-claude-haiku-4-5)

## Community Contributors
A special thanks to our contributors this month:[TensorNull](https://github.com/TensorNull), [miuosz](https://github.com/miuosz), [marsianin](https://github.com/marsianin), and [uc4w6c](https://github.com/uc4w6c)

## Support

<CardGroup cols={2}>
<Card title="Need Help?" icon="bug" href="https://github.com/Portkey-AI/gateway/issues">
Open an issue on GitHub
</Card>
<Card title="Join Us" icon="discord" href="https://portkey.wiki/community">
Get support in our Discord
</Card>
</CardGroup>