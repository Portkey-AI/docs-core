---
title: "December" 
---

As we closed out the year, December focused on strengthening the core platform. 

We shipped updates across routing, integrations, models, and guardrails to make production AI systems more predictable and easier to operate at scale. 

We are starting the new year with Portkey AI Builders Challenge, bringing the community together to build and debug real-world AI systems.


## Summary


| Area | Key Highlights |
|---|---|
| **Platform** | • Sticky load balancing for session-consistent routing |
| **Integrations** | • AWS Bedrock AgentCore support<br />• OpenCode integration |
| **Guardrails** | • Block Tools guardrail for controlling tool usage |
| **Gateway (Models & Providers)** | • GPT-5.2<br />• Gemini 3 Flash Preview<br />• New provider: OCI |
| **Gateway (Enhancements)** | • Anthropic models via Azure AI Foundry (`/messages`)<br />• OpenAI `conversation` & `modalities` params + Sora pricing<br />• Gemini / Vertex reasoning & image config support<br />• Azure image editing (`/v1/images/edits`) |
| **Community & Events** | • Portkey AI Builders Challenge |


## How Hedy AI delivers reliable real-time AI coaching for 20,000 users

Hedy AI is a real-time AI coaching assistant designed to help professionals bring their best selves to every conversation.

Julian Pscheid, Founder & CEO of Hedy AI, shares how Hedy supports over 20,000 individual users by delivering real-time understanding, intelligent suggestions, and long-term conversational memory during and after meetings.

<Frame>
 <iframe
   width="700"
   height="394"
   src="https://www.youtube.com/embed/T8P4vVMI424?si=oX2kBtpfD-pkvLaj"
   title="Hedy AI"
   frameBorder="0"
   allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
   allowFullScreen
 ></iframe>
</Frame>


## Platform

### Sticky load balancing

Sticky load balancing ensures that requests sharing the same identifier are consistently routed to the same target.

This is especially useful for:

- Maintaining conversation context across requests
- Ensuring consistent model behavior during A/B testing
- Session-based or user-specific routing.

See how you can set it up [here](https://portkey.ai/docs/product/ai-gateway/load-balancing#sticky-load-balancing).

## Integrations

## AWS Bedrock AgentCore support

Because AgentCore supports OpenAI-compatible frameworks, you can integrate Portkey without modifying your agent code while keeping AgentCore’s runtime, gateway, and memory services intact.
With this setup, you get:

- A unified gateway for 1600+ models across providers
- Production telemetry (traces, logs, metrics) for AgentCore invocations
- Reliability controls such as fallbacks, load balancing, and timeouts
- Centralized governance over provider access, spend, and policies using Portkey API keys

See how you can implement it [here](https://portkey.ai/docs/integrations/agents/agentcore).

## OpenCode integration

OpenCode’s model-agnostic, terminal-first workflow can now be run with Portkey underneath, allowing teams to add access control, budgets, limits, and observability at the platform layer, without changing how developers use OpenCode.

See how you can set it up [here](https://portkey.ai/docs/integrations/libraries/opencode).


## Guardrails

### Block Tools

We added a new guardrail that allows you to control which AI tools can be used in requests. Supported tool types include:
`function`, `web_search_preview`, `web_search`, `file_search`, `code_interpreter`, `computer_use`, and `mcp`.


## Gateway
### New models & providers


<div style={{ display: "flex", gap: "2rem", flexWrap: "wrap" }}>
 <div style={{ flex: 1, minWidth: 300 }}>
   <ul>
     <li><b>GPT-5.2</b>: Frontier-grade model now available.</li>
     <li><b>Gemini 3 Flash preview</b>: Google’s latest model with improved reasoning performance.</li>
   </ul>
 </div>


 <div style={{ flex: 1, minWidth: 300 }}>
   <ul>
     <li><b>OCI</b>: LLM provider for enteprises that are integrated with Oracle Cloud workloads</li>
     </ul>
 </div>
</div>


### Model & Provider Enhancements

<ul>
 <li>Azure AI Foundry: access Anthropic models using the native `/messages` endpoint</li>
 <li>OpenAI: Added support for `conversation` & `modalities` parameters and pricing for Sora models.</li>
 <li>Gemini / Vertex AI: Added support for `reasoning_effort`, mapping OpenAI-style reasoning levels to Gemini’s thinkingLevel. </li>
 <li>Gemini/Vertex AI: Added support for `image_config` to control image generation settings such as `aspect_ratio` and `image_size`</li>
 <li>Azure AI: Added support for the  `/v1/images/edits` endpoint for image editing workflows.</li>
</ul>


## Community & Events

### Portkey AI Builders Challenge

This challenge is designed to identify engineers who can think in systems, debug real problems, and work close to production. Exciting rewards for top-performing participants! 

If you'd like to participate, please register [here](https://hackculture.io/hackathons/portkey-ai-builder-challenge)
<a href="https://hackculture.io/hackathons/portkey-ai-builder-challenge"><img src="https://hackcultureplatform.blob.core.windows.net/event-assets/hackathons/6952754a6316f9715967e67c/upload_1767085992917_q8jl5b.jpeg" alt="portkey-hackathon" style={{maxWidth: "80%", borderRadius: "8px", margin: "24px 0"}} /></a>

## Resources
* **Blog**: [Understanding MCP authorization](https://portkey.ai/blog/understanding-mcp-authorization)
* **Blog**: [AI audit checklist](https://portkey.ai/blog/ai-audit-checklist-for-internal-ai-platforms)
* **Blog**: [OpenCode: token usage, costs and model access control](https://portkey.ai/blog/opencode-token-usage-costs-and-access-control)


## Community Contributors
A special thanks to our contributors this month:[yuval-qf](https://github.com/yuval-qf), [miguelmanlyx](https://github.com/miguelmanlyx),  [eliasto](https://github.com/eliasto), [arturfromtabnine](https://github.com/arturfromtabnine), [joshweimer-patronusai](https://github.com/jroberts2600), 
[stefan-jiroveanu](https://github.com/stefan-jiroveanu), [juzhiyuan](https://github.com/juzhiyuan), and [ShivamB25](https://github.com/ShivamB25)

## Support

<CardGroup cols={2}>
<Card title="Need Help?" icon="bug" href="https://github.com/Portkey-AI/gateway/issues">
Open an issue on GitHub
</Card>
<Card title="Join Us" icon="discord" href="https://portkey.wiki/community">
Get support in our Discord
</Card>
</CardGroup>

