---
title: "What is Portkey?"
description: Portkey AI is a comprehensive platform designed to streamline and enhance AI integration for developers and organizations. It serves as a unified interface for interacting with over 250 AI models, offering advanced tools for control, visibility, and security in your Generative AI apps.
---



It takes 2 mins to integrate and with that, it starts monitoring all of your LLM requests and makes your app resilient, secure, performant, and more accurate at the same time.

Here's a product walkthrough (3 mins):

<iframe width="100%" height="400px" src="https://www.youtube.com/embed/9aO340Hew2I?si=K988Sxs_A1qJg2ag" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Integrate in 3 Lines of Code

<CodeGroup>

```Python python
from portkey_ai import Portkey

portkey = Portkey(
    api_key="YOUR_PORTKEY_API_KEY",
    virtual_key="YOUR_VIRTUAL_KEY"
)

chat_complete = portkey.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
print(chat_complete.choices[0].message.content)
```

```js node
import Portkey from 'portkey-ai';

const portkey = new Portkey({
  apiKey: "YOUR_PORTKEY_API_KEY",
  virtualKey: "YOUR_VIRTUAL_KEY"
});

async function createChatCompletion() {
  const chat_complete = await portkey.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: "Hello!" }
    ]
  });
  console.log(chat_complete.choices[0].message.content);
}

createChatCompletion();
```

```cURL cURL
curl https://api.portkey.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "x-portkey-api-key: YOUR_PORTKEY_API_KEY" \
  -H "x-portkey-virtual-key: YOUR_VIRTUAL_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

```Python OpenAI Python SDK
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = OpenAI(
    api_key="YOUR_OPENAI_API_KEY",
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="openai",
        api_key="YOUR_PORTKEY_API_KEY"
    )
)

chat_complete = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
print(chat_complete.choices[0].message.content)
```

```js OpenAI Node SDK
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const openai = new OpenAI({
  apiKey: 'YOUR_OPENAI_API_KEY',
  baseURL: PORTKEY_GATEWAY_URL,
  defaultHeaders: createHeaders({
    provider: "openai",
    apiKey: "YOUR_PORTKEY_API_KEY"
  })
});

async function createChatCompletion() {
  const chat_complete = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: "Hello!" }
    ]
  });
  console.log(chat_complete.choices[0].message.content);
}

createChatCompletion();
```
</CodeGroup>

<Check>
  While you're here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!
</Check>


### Languages Supported

| Language   | Supported Library                                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------------------|
| Javascript | [portkey-node-sdk](https://github.com/Portkey-AI/portkey-node-sdk)<br/>[openai-node](https://github.com/openai/openai-node) |
| Python     | [portkey-python-sdk](https://github.com/Portkey-AI/portkey-python-sdk)<br/>[openai-python](https://github.com/openai/openai-python) |
| Go         | [go-openai](https://github.com/sashabaranov/go-openai)                                                                      |
| Java       | [openai-java](https://github.com/TheoKanning/openai-java)                                                                   |
| Rust       | [async-openai](https://github.com/64bit/async-openai)                                                                       |
| Ruby       | [ruby-openai](https://github.com/alexrudall/ruby-openai)                                                                    |

### AI Providers Supported

Portkey is multimodal by default - along with chat and text models, we also support audio, vision, and image generation models.

| AI Provider | Status |
|-------------|--------|
| [OpenAI](../integrations/llms/openai/) |`fully supported` | `public` |
| [Anthropic](../integrations/llms/anthropic/) |`fully supported` | `public` |
| [Azure OpenAI](../integrations/llms/azure-openai) |`fully supported` | `public` |
| [Cohere](../integrations/llms/cohere) |`fully supported` | `public` |
| [Anyscale](../integrations/llms/anyscale-llama2-mistral-zephyr) |`fully supported` | `public` |
| [Google Palm](../integrations/llms/google-palm) |`fully supported` | `public` |
| [Google Gemini](../integrations/llms/gemini) |`fully supported` | `public` |
| [Together AI](../integrations/llms/together-ai) |`fully supported` | `public` |
| [Perplexity](../integrations/llms/perplexity-ai) |`fully supported` | `public` |
| [Mistral](../integrations/llms/mistral-ai) |`fully supported` | `public` |
| [Stability](../integrations/llms/stability-ai) |`fully supported` | `public` |
| [Nomic](../integrations/llms/nomic) |`fully supported` | `public` |
| [AWS Bedrock](../integrations/llms/aws-bedrock) |`fully supported` | `public` |
| [Ollama](../integrations/llms/ollama) |`fully supported` | `public` |
| AzureML | `partially supported` ||
| [BYOLLM](../integrations/llms/byollm) |`fully supported` | `public` |
| [Jina AI](../integrations/llms/jina-ai) |`fully supported` | `public` |
| [Fireworks AI](../integrations/llms/fireworks) |`fully supported` | `public` |
| [LocalAI](../integrations/llms/local-ai) | `partially supported` |`public` |
| [Predibase](../integrations/llms/predibase) |`fully supported` | `public` |
| [ZhipuAI](../integrations/llms/zhipu) (ChatGLM) |`fully supported` | `public` |
| [Deepinfra](../integrations/llms/deepinfra) |`fully supported` | `public` |
| [Lingyi (01.ai)](../integrations/llms/lingyi-01.ai) |`fully supported` | `public` |
| [Openrouter](../integrations/llms/openrouter) |`fully supported` | `public` |
| [Moonshot](../integrations/llms/moonshot) |`fully supported` | `public` |
| [AI21](../integrations/llms/ai21) |`fully supported` | `public` |
| [Reka AI](../integrations/llms/reka-ai) |`fully supported` | `public` |
| [Workers AI](../integrations/llms/workers-ai) |`fully supported` | `public` |
| [Deepbricks](../integrations/llms/Deepbricks)|`fully supported` | `public` |
| [SiliconFlow](../integrations/llms/SiliconFlow) |`fully supported` | `public` |

[View all the supported integration guides](../integrations/llms/).

### Frameworks Supported

| Framework | Status |
|-----------|--------|
| [Langchain](../integrations/libraries/langchain-python) | `native` |`python` | `typescript` |
| [Llamaindex](../integrations/libraries/llama-index-python) | `native` |`python` | `typescript` |
| [Autogen](../integrations/libraries/autogen) | `native` |`python` | |
| [Vercel](../integrations/libraries/vercel/vercel) | `native` | `typescript` |
| [Instructor](../integrations/libraries/instructor) | `native` |`python` | `typescript` |
| [Promptfoo](../integrations/libraries/promptfoo) | `native` | `typescript` |
| [CrewAI](https://git.new/CrewAI-Portkey) | `native` |`python` |
