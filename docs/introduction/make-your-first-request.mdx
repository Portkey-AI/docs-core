---
title: "Make Your First Request"
description: "Integrate Portkey and analyze your first LLM call in 2 minutes!"
---

## 1\. Get your Portkey API Key

[Create](https://app.portkey.ai/signup) or [log in](https://app.portkey.ai/login) to your Portkey account. Grab your account's API key from the "Settings" page.

<Frame caption="Copy your Portkey account API key">
  <img src="/images/welcome/welcome-2.gif" alt="Copy your Portkey account API key" />
</Frame>

Based on your access level, you might see the relevant permissions on the API key modal - tick the ones you'd like, name your API key, and save it.

## 2\. Integrate Portkey

Portkey offers a variety of integration options, including SDKs, REST APIs, and native connections with platforms like OpenAI, Langchain, and LlamaIndex, among others.

### Through the OpenAI SDK

If you're using the **OpenAI SDK**, import the Portkey SDK and configure it within your OpenAI client object:

<Card title="OpenAI" href="/docs/integrations/llms/openai" />


### Portkey SDK

You can also use the **Portkey SDK / REST APIs** directly to make the chat completion calls. This is a more versatile way to make LLM calls across any provider:

<Card title="SDK" href="/docs/api-reference/portkey-sdk-client" />


Once, the integration is ready, you can view the requests reflect on your Portkey dashboard.

<Frame>
  <img src="https://docs.portkey.ai/~gitbook/image?url=https%3A%2F%2F2878743244-files.gitbook.io%2F%7E%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252Fy3MCfQqftZOnHqSmVV5x%252Fuploads%252FzWw4VMOnC5rSBQpeJQOG%252Fanalytics_logs.gif%3Falt%3Dmedia%26token%3Daf8b4689-37d2-4298-ac9a-91c21f9cfc2b&width=400&dpr=2&quality=100&sign=edcf8ba2&sv=1"/>
</Frame>


### Other Integration Guides

<CardGroup cols={3}>
  <Card title="Azure OpenAI" href="/docs/integrations/llms/azure-openai" />
  <Card title="Anthropic" href="/docs/integrations/llms/anthropic" />
  <Card title="Langchain" href="/docs/integrations/libraries/langchain-python" />
  <Card title="LlamaIndex" href="/docs/integrations/libraries/llama-index-python" />
  <Card title="Ollama" href="/docs/integrations/llms/ollama" />
  <Card title="Others" href="/docs/provider-endpoints/gateway-for-other-apis" />
</CardGroup>

## 3\. Next Steps

Now that you're up and running with Portkey, you can dive into the various Portkey features to learn about all of the supported functionalities:

<CardGroup cols={3}>
  <Card title="Observability" href="/docs/product/observability/" />
  <Card title="AI Gateway" href="/docs/product/ai-gateway" />
  <Card title="Prompt Library" href="/docs/product/prompt-library" />
  <Card title="Autonomous Fine-Tuning" href="/docs/product/autonomous-fine-tuning" />
  <Card title="Guardrails" href="/docs/product/guardrails" />
  <Card title="Enterprise" href="/docs/product/enterprise-offering" />

</CardGroup>

<Check>
While you're here, why not [give us a star](https://git.new/ai-gateway-docs)? It helps us a lot!
</Check>
