---
title: "Anthropic"
---

Portkey provides a robust and secure gateway to facilitate the integration of various Large Language Models (LLMs) into your applications, including [Anthropic's Claude APIs](https://docs.anthropic.com/claude/reference/getting-started-with-the-api).

With Portkey, you can take advantage of features like fast AI gateway access, observability, prompt management, and more, all while ensuring the secure management of your LLM API keys through a [virtual key](/docs/product/ai-gateway/virtual-keys) system.
<Note>Provider Slug. **`anthropic`**</Note>


## Portkey SDK Integration with Anthropic

Portkey provides a consistent API to interact with models from various providers. To integrate Anthropic with Portkey:

### 1\. Install the Portkey SDK

Add the Portkey SDK to your application to interact with Anthropic's API through Portkey's gateway.

<Tabs>
    <Tab title="NodeJS">
        ```
        npm install --save portkey-ai
        ```
    </Tab>
    <Tab title="Python">
        ```
        pip install portkey-ai
        ```
    </Tab>
  </Tabs>




### 2\. Initialize Portkey with the Virtual Key

To use Anthropic with Portkey, [get your Anthropic API key from here](https://console.anthropic.com/settings/keys), then add it to Portkey to create your Anthropic virtual key.

<Tabs>
    <Tab title="NodeJS SDK">

```js
import Portkey from 'portkey-ai'


const portkey = new Portkey({

    apiKey: "PORTKEY_API_KEY", // defaults to process.env["PORTKEY_API_KEY"]

    virtualKey: "VIRTUAL_KEY" // Your Anthropic Virtual Key

})
```

    </Tab>
    <Tab title="Python SDK">

```python
from portkey_ai import Portkey

portkey = Portkey(

    api_key="PORTKEY_API_KEY",  # Replace with your Portkey API key

    virtual_key="VIRTUAL_KEY"   # Replace with your virtual key for Anthropic

)
```
    </Tab>
  <Tab title="OpenAI Python SDK">

```python
from openai import OpenAI

from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = OpenAI(

    api_key="ANTHROPIC_API_KEY",

    base_url=PORTKEY_GATEWAY_URL,

    default_headers=createHeaders(

        api_key="PORTKEY_API_KEY",

        provider="anthropic"

    )

)
```

    </Tab>
    <Tab title="OpenAI Node SDK">

```js
import OpenAI from "openai";

import { PORTKEY_GATEWAY_URL, createHeaders } from "portkey-ai";

const client = new OpenAI({

  apiKey: "ANTHROPIC_API_KEY",

  baseURL: PORTKEY_GATEWAY_URL,

  defaultHeaders: createHeaders({

    provider: "anthropic",

    apiKey: "PORTKEY_API_KEY",

  }),

});
```
    </Tab>
  </Tabs>



### 3\. Invoke Chat Completions with Anthropic

Use the Portkey instance to send requests to Anthropic. You can also override the virtual key directly in the API call if needed.


<Tabs>
    <Tab title="NodeJS SDK">

```js
const chatCompletion = await portkey.chat.completions.create({

    messages: [{ role: 'user', content: 'Say this is a test' }],

    model: 'claude-3-opus-20240229',

    max_tokens: 250 // Required field for Anthropic

});

console.log(chatCompletion.choices[0].message.content);
```

    </Tab>
    <Tab title="Python SDK">

```python
chat_completion = portkey.chat.completions.create(

    messages= [{ "role": 'user', "content": 'Say this is a test' }],

    model= 'claude-3-opus-20240229',

    max_tokens=250 # Required field for Anthropic

)


print(chat_completion.choices[0].message.content)
```

    </Tab>
  <Tab title="OpenAI Python SDK">

```python
chat_completion = client.chat.completions.create(

    messages = [{ "role": 'user', "content": 'Say this is a test' }],

    model = 'claude-3-opus-20240229',

    max_tokens = 250

)

print(chat_completion.choices[0].message.content)
```

    </Tab>
    <Tab title="OpenAI Node SDK">

```js
async function main() {

    const chatCompletion = await client.chat.completions.create({

        model: "claude-3-opus-20240229",

        max_tokens: 1024,

        messages: [{ role: "user", content: "Hello, Claude" }],

    });

    console.log(chatCompletion.choices[0].message.content);

}

main();
```
    </Tab>
  </Tabs>




## How to Use Anthropic System Prompt

With Portkey, we make Anthropic models interoperable with the OpenAI schema and SDK methods. So, instead of passing the `system` prompt separately, you can pass it as part of the `messages` body, similar to OpenAI:

<Tabs>
    <Tab title="NodeJS">

```js
const chatCompletion = await portkey.chat.completions.create({

    messages: [

        { role: 'system', content: 'Your system prompt' },

        { role: 'user', content: 'Say this is a test' }

    ],

    model: 'claude-3-opus-20240229',

    max_tokens: 250

});

console.log(chatCompletion.choices);
```

    </Tab>
    <Tab title="Python">

```python
completion = portkey.chat.completions.create(

    messages= [

        { "role": 'system', "content": 'Your system prompt' },

        { "role": 'user', "content": 'Say this is a test' }

    ],

    model= 'claude-3-opus-20240229',

    max_tokens=250 # Required field for Anthropic

)


print(completion.choices)
```

    </Tab>

  </Tabs>



## Vision Chat Completion Usage


Portkey's multimodal Gateway fully supports Anthropic's vision models `claude-3-sonnet`, `claude-3-haiku`,  `claude-3-opus`, and the latest `claude-3.5-sonnet`. 
Portkey follows the OpenAI schema, which means you can send your image data to Anthropic in the same format as OpenAI.


<Note>
   - Anthropic ONLY accepts `base64` -encoded images. Unlike OpenAI, it **does not** support  `image URLs`.
- With Portkey, you can use the same format to send base64-encoded images to both Anthropic and OpenAI models.


</Note>

Here's an example using Anthropic `claude-3.5-sonnet` model

<Tabs>
  <Tab title="Python">
    ```python
    import base64
    import httpx
    from portkey_ai import Portkey

    # Fetch and encode the image
    image_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"
    image_data = base64.b64encode(httpx.get(image_url).content).decode("utf-8")

    # Initialize the Portkey client
    portkey = Portkey(
        api_key="PORTKEY_API_KEY",  # Replace with your Portkey API key
        virtual_key="VIRTUAL_KEY"   # Add your provider's virtual key
    )

    # Create the request
    response = portkey.chat.completions.create(
        model="claude-3-5-sonnet-20240620",
        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant, who describes imagse"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}"
                        }
                    }
                ]
            }
        ],
        max_tokens=1400,
    )
    print(response)
    ```
  </Tab>
  <Tab title="NodeJS">
    ```javascript
    import Portkey from 'portkey-ai';

    // Initialize the Portkey client
    const portkey = new Portkey({
      apiKey: "PORTKEY_API_KEY", // Replace with your Portkey API key
      virtualKey: "VIRTUAL_KEY" // Add your anthropic's virtual key
    });

    // Generate a chat completion
    async function getChatCompletionFunctions() {
        const response = await portkey.chat.completions.create({
          model: "claude-3-5-sonnet-20240620",
          messages: [
            {
              role: "system",
              content: "You are a helpful assistant who describes images."
            },
            {
              role: "user",
              content: [
                { type: "text", text: "What's in this image?" },
                {
                  type: "image_url",
                  image_url: {
                    url: "data:image/jpeg;base64,BASE64_IMAGE_DATA"
                  }
                }
              ]
            }
          ],
          max_tokens: 300
        });
        console.log(response);
      }
    // Call the function
    getChatCompletionFunctions();
    ```
  </Tab>
  <Tab title="OpenAI NodeJS">
    ```javascript
    import OpenAI from 'openai'; // We're using the v4 SDK
    import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai'

    const openai = new OpenAI({
      apiKey: 'ANTHROPIC_API_KEY', // defaults to process.env["OPENAI_API_KEY"],
      baseURL: PORTKEY_GATEWAY_URL,
      defaultHeaders: createHeaders({
        provider: "openai",
        apiKey: "PORTKEY_API_KEY" // defaults to process.env["PORTKEY_API_KEY"]
      })
    });

    // Generate a chat completion with streaming
    async function getChatCompletionFunctions(){
      const response = await openai.chat.completions.create({
        model: "gpt-4-vision-preview",
        messages: [
          {
            role: "user",
            content: [
              { type: "text", text: "What's in this image?" },
              {
                type: "image_url",
                image_url:
                  "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
              },
            ],
          },
        ],
      });
      
      console.log(response)

    }
    await getChatCompletionFunctions();
    ```
  </Tab>
  <Tab title="OpenAI Python">
    ```python
    from openai import OpenAI
    from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

    openai = OpenAI(
        api_key='Anthropic_API_KEY',
        base_url=PORTKEY_GATEWAY_URL,
        default_headers=createHeaders(
            provider="anthropic",
            api_key="PORTKEY_API_KEY"
        )
    )


    response = openai.chat.completions.create(
       model="claude-3-5-sonnet-20240620",
        messages=[
            {
                "role": "system",
                "content": "You are a helpful assistant, who describes imagse"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base_64_encoded_image}"
                        }
                    }
                ]
            }
        ],
        max_tokens=1400,
    )

    print(response)
    ```
  </Tab>
  <Tab title="REST">
    ```bash
    curl "https://api.portkey.ai/v1/chat/completions" \
      -H "Content-Type: application/json" \
      -H "x-portkey-api-key: $PORTKEY_API_KEY" \
      -H "x-portkey-provider: anthropic" \
      -H "x-api-key: $ANTHROPIC_API_KEY" \
      -d '{
        "model": "claude-3-5-sonnet-20240620",
        "messages": [
          {
            "role": "system",
            "content": "You are a helpful assistant who describes images."
          },
          {
            "role": "user",
            "content": [
              {
                "type": "text",
                "text": "What's in this image?"
              },
              {
                "type": "image_url",
                "image_url": {
                  "url": "data:image/jpeg;base64,BASE64_IMAGE_DATA"
                }
              }
            ]
          }
        ],
        "max_tokens": 300
      }'
    ```
  </Tab>
</Tabs>

#### [API Reference](#vision-chat-completion-usage)

On completion, the request will get logged in Portkey where any image inputs or outputs can be viewed. Portkey will automatically render the base64 images to help you debug any issues quickly.

**For more info, check out this guide:**

<Card title="Vision" href="/docs/product/ai-gateway/multimodal-capabilities/vision">
  Learn more about Vision capabilities
</Card>

## Prompt Caching

Portkey also works with Anthropic's new prompt caching feature and helps you save time & money for all your Anthropic requests. Refer to this guide to learn how to enable it:

<Card title="Prompt Caching" href="/docs/integrations/llms/anthropic/prompt-caching">
</Card>



## Managing Anthropic Prompts

You can manage all prompts to Anthropic in the [Prompt Library](/docs/product/prompt-library). All the current models of Anthropic are supported and you can easily start testing different prompts.

Once you're ready with your prompt, you can use the `portkey.prompts.completions.create` interface to use the prompt in your application.

## Next Steps

The complete list of features supported in the SDK are available on the link below.

<Card title="SDK" href="/docs/api-reference/portkey-sdk-client">
</Card>


You'll find more information in the relevant sections:

1. [Add metadata to your requests](/docs/product/observability/metadata)
2. [Add gateway configs to your Anthropic requests](/docs/product/ai-gateway/configs)
3. [Tracing Anthropic requests](/docs/product/observability/traces)
4. [Setup a fallback from OpenAI to Anthropic's Claude APIs](/docs/product/ai-gateway/fallbacks)
