---
title: "Pydantic Logfire"
description: "Modern Python observability with automatic OpenAI instrumentation and intelligent gateway routing"
---

[Pydantic Logfire](https://pydantic.dev/logfire) is a modern observability platform from the creators of Pydantic, designed specifically for Python applications. It provides automatic instrumentation for popular libraries including OpenAI, Anthropic, and other LLM providers, making it an excellent choice for AI application monitoring.

<Info>
Logfire's automatic instrumentation combined with Portkey's intelligent gateway creates a powerful observability stack where every trace is enriched with routing decisions, cache performance, and cost optimization data.
</Info>

## Why Logfire + Portkey?

<CardGroup cols={2}>
<Card title="Zero-Code OpenAI Instrumentation" icon="wand-magic-sparkles">
Logfire automatically instruments OpenAI SDK calls without any code changes
</Card>
<Card title="Gateway Intelligence" icon="brain">
Portkey adds routing context, fallback decisions, and cache performance to every trace
</Card>
<Card title="Python-First Design" icon="python">
Built by the Pydantic team specifically for Python developers
</Card>
<Card title="Real-Time Insights" icon="bolt">
See traces immediately with actionable optimization opportunities
</Card>
</CardGroup>

## Quick Start

### Prerequisites

- Python
- Portkey account with API key
- OpenAI API key (or use Portkey's virtual keys)

### Step 1: Install Dependencies

Install the required packages for Logfire and Portkey integration:

```bash
pip install logfire openai portkey-ai
```

### Step 2: Basic Setup - Send Traces to Portkey

First, let's configure Logfire to send traces to Portkey's OpenTelemetry endpoint:

```python
import os
import logfire

# Configure OpenTelemetry export to Portkey
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://api.portkey.ai/v1/logs/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = "x-portkey-api-key=YOUR_PORTKEY_API_KEY"

# Initialize Logfire
logfire.configure(
    service_name='my-llm-app',
    send_to_logfire=False,  # Disable sending to Logfire cloud
)

# Instrument OpenAI globally
logfire.instrument_openai()
```

### Step 3: Complete Setup - Use Portkey's Gateway

For the best experience, route your LLM calls through Portkey's gateway to get automatic optimizations:

```python
import logfire
import os
from portkey_ai import createHeaders
from openai import OpenAI

# Configure OpenTelemetry export
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://api.portkey.ai/v1/logs/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = "x-portkey-api-key=YOUR_PORTKEY_API_KEY"

# Initialize Logfire
logfire.configure(
    service_name='my-llm-app',
    send_to_logfire=False,
)

# Create OpenAI client with Portkey's gateway
client = OpenAI(
    api_key="YOUR_OPENAI_API_KEY",  # Or use a dummy value with virtual keys
    base_url="https://api.portkey.ai/v1",
    default_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_VIRTUAL_KEY"  # Optional: Use Portkey's secure key management
    )
)

# Instrument the Portkey-configured client
logfire.instrument_openai(client)
```

### Step 4: Make Instrumented LLM Calls

Now your LLM calls are automatically traced by Logfire and enhanced by Portkey:

```python
# Simple chat completion - automatically traced
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {
            "role": "user",
            "content": "Explain the benefits of observability in LLM applications"
        }
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```




## Next Steps

<CardGroup cols={2}>
<Card title="Configure Gateway" icon="gear" href="/product/ai-gateway/configs">
Set up intelligent routing, fallbacks, and caching
</Card>
<Card title="Explore Virtual Keys" icon="key" href="/product/ai-gateway/virtual-keys">
Secure your API keys with Portkey's vault
</Card>
<Card title="View Analytics" icon="chart-line" href="/product/observability/analytics">
Analyze costs, performance, and usage patterns
</Card>
<Card title="Set Up Budget & Rate Limts" icon="bell" href="/product/administration/enforce-budget-and-rate-limit">
    Set Rate and Budget Limits per model/user/api-key
</Card>
</CardGroup>

---

## See Your Traces in Action

Once configured, navigate to the [Portkey dashboard](https://app.portkey.ai/logs) to see your Logfire instrumentation combined with gateway intelligence:

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>