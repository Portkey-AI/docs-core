---
title: "Pydantic Logfire"
description: "Python-first observability with automatic OpenAI instrumentation"
---

[Pydantic Logfire](https://pydantic.dev/logfire) provides modern Python observability with automatic instrumentation for OpenAI, Anthropic, and other LLM providers. Combined with Portkey, get automatic traces plus gateway features like caching, fallbacks, and load balancing.

## Why Logfire + Portkey?

<CardGroup cols={2}>
<Card title="Zero-Code Instrumentation" icon="wand-magic-sparkles">
Automatic OpenAI SDK instrumentation without code changes
</Card>
<Card title="Python-First Design" icon="python">
Built by the Pydantic team specifically for Python developers
</Card>
<Card title="Real-Time Insights" icon="bolt">
See traces immediately with actionable optimization opportunities
</Card>
<Card title="Gateway Intelligence" icon="brain">
Portkey adds caching, fallbacks, and load balancing to every request
</Card>
</CardGroup>

## Quick Start

```bash
pip install logfire openai
```

```python
import os
import logfire
from openai import OpenAI

# Send traces to Portkey
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://api.portkey.ai/v1/logs/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = "x-portkey-api-key=YOUR_PORTKEY_API_KEY"

# Initialize Logfire
logfire.configure(service_name='my-llm-app', send_to_logfire=False)

# Use Portkey gateway
client = OpenAI(
    api_key="YOUR_PORTKEY_API_KEY",
    base_url="https://api.portkey.ai/v1"
)

# Instrument the client
logfire.instrument_openai(client)

response = client.chat.completions.create(
    model="@openai-prod/gpt-4.1",  # Provider slug from Model Catalog
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>

## Setup

1. [Add provider](https://app.portkey.ai/model-catalog) in Model Catalog â†’ get provider slug (e.g., `@openai-prod`)
2. Get [Portkey API key](https://app.portkey.ai/api-keys)
3. Use `model="@provider-slug/model-name"` in requests

## Next Steps

<CardGroup cols={2}>
<Card title="Gateway Configs" icon="gear" href="/product/ai-gateway/configs">
Fallbacks, caching, and load balancing
</Card>
<Card title="Model Catalog" icon="server" href="/product/model-catalog">
Manage providers and credentials
</Card>
<Card title="Analytics" icon="chart-line" href="/product/observability/analytics">
Cost and performance insights
</Card>
<Card title="Logfire Docs" icon="book" href="https://pydantic.dev/logfire">
Official documentation
</Card>
</CardGroup>

---

## See Your Traces in Action

Once configured, view your Logfire instrumentation combined with Portkey gateway intelligence in the [Portkey dashboard](https://app.portkey.ai/logs):

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>
