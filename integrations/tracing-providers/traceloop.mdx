---
title: "Traceloop (OpenLLMetry)"
---

[Traceloop's OpenLLMetry](https://www.traceloop.com/docs/openllmetry/introduction) is an open source project that allows you to easily start monitoring and debugging the execution of your LLM app.

<Info>
Traceloop's non-intrusive instrumentation combined with Portkey's intelligent gateway provides comprehensive observability without modifying your application code, while adding routing intelligence, caching, and failover capabilities.
</Info>

## Why Traceloop + Portkey?

<CardGroup cols={2}>
<Card title="Non-Intrusive Monitoring" icon="eye">
Automatic instrumentation without changing your application code
</Card>
<Card title="OpenTelemetry Native" icon="chart-network">
Built on industry-standard OpenTelemetry for maximum compatibility
</Card>
<Card title="Flexible Export Options" icon="arrows-split-up-and-left">
Send traces to Portkey or any OpenTelemetry-compatible backend
</Card>
<Card title="Enhanced Intelligence" icon="brain">
Portkey adds gateway features like caching, fallbacks, and load balancing
</Card>
</CardGroup>

## Quick Start

### Prerequisites

- Python
- Portkey account with API key
- OpenAI API key (or use Portkey's virtual keys)

### Step 1: Install Dependencies

Install the required packages for Traceloop and Portkey integration:

```bash
pip install openai traceloop-sdk portkey-ai
```

### Step 2: Initialize Traceloop

Configure Traceloop to send traces to Portkey's OpenTelemetry endpoint:

```python
from traceloop.sdk import Traceloop

# Initialize Traceloop with Portkey's endpoint
Traceloop.init(
    disable_batch=True,  # Process traces immediately
    api_endpoint="https://api.portkey.ai/v1/logs/otel",
    headers="x-portkey-api-key=YOUR_PORTKEY_API_KEY",
    telemetry_enabled=False  # Disable Traceloop's own telemetry
)
```

### Step 3: Configure Portkey Gateway

Set up the OpenAI client to use Portkey's intelligent gateway:

```python
from openai import OpenAI
from portkey_ai import createHeaders

# Use Portkey's gateway for intelligent routing
client = OpenAI(
    api_key="YOUR_OPENAI_API_KEY",  # Or use a dummy value with virtual keys
    base_url="https://api.portkey.ai/v1",
    default_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_VIRTUAL_KEY"  # Optional: Use Portkey's secure key management
    )
)
```

### Step 4: Make Instrumented LLM Calls

Your LLM calls are now automatically traced by Traceloop and enhanced by Portkey:

```python
# Make calls through Portkey's gateway
# Traceloop automatically instruments the call
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {
            "role": "user",
            "content": "Explain the benefits of OpenTelemetry for LLM applications"
        }
    ],
    temperature=0.7
)

print(response.choices[0].message.content)

# You now get:
# 1. Automatic, non-intrusive tracing from Traceloop
# 2. Gateway features from Portkey (caching, fallbacks, routing)
# 3. Combined insights in Portkey's dashboard
```

## Complete Example

Here's a full example bringing everything together:

```python
from traceloop.sdk import Traceloop
from openai import OpenAI
from portkey_ai import createHeaders

# Step 1: Initialize Traceloop with Portkey endpoint
Traceloop.init(
    disable_batch=True,
    api_endpoint="https://api.portkey.ai/v1/logs/otel",
    headers="x-portkey-api-key=YOUR_PORTKEY_API_KEY",
    telemetry_enabled=False
)

# Step 2: Configure Portkey Gateway
client = OpenAI(
    api_key="YOUR_OPENAI_API_KEY",
    base_url="https://api.portkey.ai/v1",
    default_headers=createHeaders(
        api_key="YOUR_PORTKEY_API_KEY",
        virtual_key="YOUR_VIRTUAL_KEY"
    )
)

# Step 3: Make instrumented calls
response = client.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What makes observability important for production AI?"}
    ]
)

print(response.choices[0].message.content)
```

## Next Steps

<CardGroup cols={2}>
<Card title="Configure Gateway" icon="gear" href="/product/ai-gateway/configs">
Set up intelligent routing, fallbacks, and caching
</Card>
<Card title="Explore Virtual Keys" icon="key" href="/product/ai-gateway/virtual-keys">
Secure your API keys with Portkey's vault
</Card>
<Card title="View Analytics" icon="chart-line" href="/product/observability/analytics">
Analyze costs, performance, and usage patterns
</Card>
<Card title="Set Up Alerts" icon="bell" href="/product/observability/alerts">
Configure alerts for anomalies and performance issues
</Card>
</CardGroup>

---

## See Your Traces in Action

Once configured, navigate to the [Portkey dashboard](https://app.portkey.ai/logs) to see your Traceloop instrumentation combined with gateway intelligence:

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>