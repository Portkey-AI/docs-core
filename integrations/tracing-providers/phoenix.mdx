---
title: "Phoenix (Arize)"
description: "AI observability with OpenInference instrumentation and Portkey gateway"
---

[Arize Phoenix](https://phoenix.arize.com/) provides open-source AI observability with powerful visualization and debugging tools. Combined with Portkey, get automatic trace collection plus gateway features like caching, fallbacks, and load balancing.

## Why Phoenix + Portkey?

<CardGroup cols={2}>
<Card title="Visual Debugging" icon="magnifying-glass">
Powerful UI for exploring traces, spans, and debugging LLM behavior
</Card>
<Card title="OpenInference Standard" icon="code-branch">
Industry-standard semantic conventions for AI/LLM observability
</Card>
<Card title="Evaluation Tools" icon="chart-column">
Built-in tools for evaluating model performance and behavior
</Card>
<Card title="Gateway Intelligence" icon="brain">
Portkey adds caching, fallbacks, and load balancing to every request
</Card>
</CardGroup>

## Quick Start

```bash
pip install arize-phoenix-otel openai openinference-instrumentation-openai
```

```python
import os
from phoenix.otel import register
from openinference.instrumentation.openai import OpenAIInstrumentor
from openai import OpenAI

# Send traces to Portkey
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://api.portkey.ai/v1/logs/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = "x-portkey-api-key=YOUR_PORTKEY_API_KEY"

# Initialize Phoenix
register(set_global_tracer_provider=False)
OpenAIInstrumentor().instrument()

# Use Portkey gateway
client = OpenAI(
    api_key="YOUR_PORTKEY_API_KEY",
    base_url="https://api.portkey.ai/v1"
)

response = client.chat.completions.create(
    model="@openai-prod/gpt-4.1",  # Provider slug from Model Catalog
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>

## Setup

1. [Add provider](https://app.portkey.ai/model-catalog) in Model Catalog â†’ get provider slug (e.g., `@openai-prod`)
2. Get [Portkey API key](https://app.portkey.ai/api-keys)
3. Use `model="@provider-slug/model-name"` in requests

## What Gets Captured

Phoenix uses OpenInference semantic conventions:

- **Messages**: Full conversation history with roles and content
- **Model Info**: Model name, temperature, and parameters
- **Token Usage**: Input/output token counts for cost tracking
- **Errors**: Detailed error information when requests fail
- **Latency**: End-to-end request timing

**Supported providers**: OpenAI, Anthropic, Bedrock, Vertex AI, Azure OpenAI, and more.

## Configuration Options

### Custom Span Attributes

Add custom attributes to your traces:

```python
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

with tracer.start_as_current_span("custom_operation") as span:
    span.set_attribute("user.id", "user123")
    span.set_attribute("session.id", "session456")
    response = client.chat.completions.create(...)
```

### Sampling Configuration

Control trace sampling for production:

```python
from opentelemetry.sdk.trace.sampling import TraceIdRatioBased

# Sample 10% of traces
register(
    set_global_tracer_provider=False,
    sampler=TraceIdRatioBased(0.1)
)
```

## Troubleshooting

<AccordionGroup>
<Accordion title="Traces not appearing in Portkey">
Ensure both `OTEL_EXPORTER_OTLP_ENDPOINT` and `OTEL_EXPORTER_OTLP_HEADERS` are correctly set before initializing Phoenix.
</Accordion>
<Accordion title="Missing instrumentation data">
Call `OpenAIInstrumentor().instrument()` before creating your OpenAI client.
</Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
<Card title="Gateway Configs" icon="gear" href="/product/ai-gateway/configs">
Fallbacks, caching, and load balancing
</Card>
<Card title="Model Catalog" icon="server" href="/product/model-catalog">
Manage providers and credentials
</Card>
<Card title="Analytics" icon="chart-line" href="/product/observability/analytics">
Cost and performance insights
</Card>
<Card title="Phoenix Docs" icon="book" href="https://phoenix.arize.com/">
Official documentation
</Card>
</CardGroup>

---

## See Your Traces in Action

Once configured, view your Phoenix instrumentation combined with Portkey gateway intelligence in the [Portkey dashboard](https://app.portkey.ai/logs):

<Frame>
  <img src="/images/product/opentelemetry.png" alt="OpenTelemetry traces in Portkey" />
</Frame>
