---
title: "Zed"
description: "Learn how to integrate Portkey's enterprise features with Zed for enhanced observability, reliability and governance."
---

Zed is a next-generation code editor built for AI-powered development. Add Portkey to get:

- **1600+ LLMs** through one interface - switch providers instantly
- **Observability** - track costs, tokens, and latency for every request
- **Reliability** - automatic fallbacks, retries, and caching
- **Governance** - budget limits, usage tracking, and team access controls

This guide shows how to configure Zed with Portkey in under 5 minutes.

<Note>
  For enterprise deployments across teams, see [Enterprise Governance](#3-enterprise-governance).
</Note>

# 1. Setup

<Steps>
<Step title="Add Provider">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) â†’ **Add Provider**.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" width="500"/>
</Frame>
</Step>

<Step title="Configure Credentials">
Select your provider (OpenAI, Anthropic, etc.), enter your API key, and create a slug like `openai-prod`.

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>
</Step>

<Step title="Get Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) and generate your Portkey API key.
</Step>
</Steps>

# 2. Configure Zed

Open `Settings.json` in Zed using Command Palette (`cmd-shift-p` / `ctrl-shift-p`) and run `zed: open settings`.

Add this configuration:

```json
{
  "language_models": {
    "openai": {
      "api_url": "https://api.portkey.ai/v1",
      "available_models": [
        {
          "name": "@openai-prod/gpt-4o",
          "display_name": "GPT-4o via Portkey",
          "max_tokens": 128000
        },
        {
          "name": "@anthropic-prod/claude-3-5-sonnet-20241022",
          "display_name": "Claude 3.5 Sonnet via Portkey",
          "max_tokens": 200000
        }
      ]
    }
  }
}
```

Then set your Portkey API key as your OpenAI API key in Zed's settings.

Done! Monitor usage in the [Portkey Dashboard](https://app.portkey.ai/dashboard).

## Switch Providers

Add more models to your `available_models` array:

```json
{
  "name": "@google-prod/gemini-2.0-flash-exp",
  "display_name": "Gemini 2.0 Flash via Portkey",
  "max_tokens": 1000000
}
```

All requests route through Portkey automatically.

<Note>
**Want fallbacks, load balancing, or caching?** Create a [Portkey Config](/product/ai-gateway/configs), attach it to your API key, and set model name to `dummy`. See [Enterprise Governance](#3-enterprise-governance) for examples.
</Note>

import AdvancedFeatures from '/snippets/portkey-advanced-features.mdx';

<AdvancedFeatures />