---
title: 'AnythingLLM'
description: 'Add usage tracking, cost controls, and security guardrails to your AnythingLLM deployment'
---

AnythingLLM is an all-in-one Desktop & Docker AI application with built-in RAG and AI agents. Add Portkey to get:

- **1600+ LLMs** through one interface - switch providers instantly
- **Observability** - track costs, tokens, and latency for every request
- **Reliability** - automatic fallbacks, retries, and caching
- **Governance** - budget limits, usage tracking, and team access controls

This guide shows how to configure AnythingLLM with Portkey in under 5 minutes.

<Note>
  For enterprise deployments across teams, see [Enterprise Governance](#3-enterprise-governance).
</Note>

# 1. Setup

<Steps>
<Step title="Add Provider">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) → **Add Provider**.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" width="500"/>
</Frame>
</Step>

<Step title="Configure Credentials">
Select your provider (OpenAI, Anthropic, etc.), enter your API key, and create a slug like `openai-prod`.

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>
</Step>

<Step title="Get Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) and generate your Portkey API key.
</Step>
</Steps>

# 2. Configure AnythingLLM

<Steps>
<Step title="Open Settings">
Launch AnythingLLM and navigate to `Settings > AI Providers > LLM`.
</Step>

<Step title="Configure Provider">
1. Select **Generic OpenAI** from the LLM Provider dropdown
2. Configure:
   - **Base URL**: `https://api.portkey.ai/v1`
   - **API Key**: Your Portkey API key
   - **Chat Model**: `@openai-prod/gpt-4o` (or your provider slug + model)
   - **Token Context Window**: Set based on your model's limits
   - **Max Tokens**: Configure according to your needs
</Step>
</Steps>

Done! Monitor usage in the [Portkey Dashboard](https://app.portkey.ai/dashboard).

## Switch Providers

Change models by updating the **Chat Model** field:

```
@anthropic-prod/claude-3-5-sonnet-20241022
@openai-prod/gpt-4o
@google-prod/gemini-2.0-flash-exp
```

All requests route through Portkey automatically.

<Note>
**Want fallbacks, load balancing, or caching?** Create a [Portkey Config](/product/ai-gateway/configs), attach it to your API key, and set Chat Model to `dummy`. See [Enterprise Governance](#3-enterprise-governance) for examples.
</Note>

# 3. Enterprise Governance

For organizations deploying AnythingLLM across teams, Portkey provides:
- **Cost Management**: Budget limits and spend tracking per team
- **Access Control**: Team-specific API keys with role-based permissions
- **Usage Analytics**: Track patterns across teams and projects
- **Model Management**: Control which models teams can access

<AccordionGroup>
  <Accordion title="Set Budget Limits Per Team">

Create team-specific providers with budget and rate limits:

1. Go to [Model Catalog](https://app.portkey.ai/model-catalog) → **Add Provider**
2. Create providers for each team (e.g., `openai-frontend`, `anthropic-backend`)
3. Set budget and rate limits per provider

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>

  </Accordion>

  <Accordion title="Control Model Access">

Provision only the models each team needs:

<Frame>
<img src="/images/product/model-catalog/model-provisioning-page.png" width="500"/>
</Frame>

Each team's provider slug gives access only to their approved models.
</Accordion>

  <Accordion title="Add Reliability Features">

Use [Portkey Configs](/product/ai-gateway/configs) for fallbacks, load balancing, and caching.

Example: Load-balance across providers

```json
{
	"strategy": { "mode": "load-balance" },
	"targets": [
		{ "override_params": { "model": "@openai-prod/gpt-4o" } },
		{ "override_params": { "model": "@anthropic-prod/claude-3-5-sonnet-20241022" } }
	]
}
```

Create configs at [Configs](https://app.portkey.ai/configs).

  </Accordion>

  <Accordion title="Create Team API Keys">

Generate API keys with metadata tracking:

```python
from portkey_ai import Portkey

portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

api_key = portkey.api_keys.create(
    name="frontend-team",
    type="organisation",
    workspace_id="YOUR_WORKSPACE_ID",
    defaults={
        "metadata": {
            "environment": "production",
            "team": "frontend"
        }
    },
    scopes=["logs.view", "configs.read"]
)
```

See [API Keys docs](/api-reference/admin-api/control-plane/api-keys/create-api-key).
  </Accordion>

  <Accordion title="Monitor Usage">

Track everything in the Portkey dashboard:
- Cost by team
- Model usage patterns
- Request volumes and errors
- Detailed logs for debugging

<Frame>
  <img src="/images/integrations/observability.png" width="600"/>
</Frame>
</Accordion>

</AccordionGroup>

# Portkey Features

### Observability
Track 40+ metrics including cost, tokens, and latency across all providers. Filter by team or project using metadata.

<Frame>
  <img src="/images/integrations/observability.png" width="600"/>
</Frame>

### Request Logs
Every request logged with complete details:
- Full request/response payloads
- Cost breakdown
- Performance metrics

<Frame>
<img src="/images/llms/openai/logs.png"></img>
</Frame>

### 1600+ LLMs
Switch between any model through one interface:

<Card title="Supported Providers" icon="layer-group" href="/integrations/llms">
View all 1600+ supported models
</Card>

### Metadata Tracking
Track custom metrics:
- Language and framework usage
- Task types (generation vs. completion)
- Project-specific patterns

<Card title="Custom Metadata" icon="tag" href="/product/observability/metadata">
</Card>

### Enterprise Access

<CardGroup cols={2}>
<Card title="Budget Controls" icon="coins" href="/product/ai-gateway/virtual-keys/budget-limits">
Set spending limits with automatic cutoffs
</Card>

<Card title="SSO" icon="key" href="/product/enterprise-offering/org-management/sso">
Enterprise SSO integration
</Card>

<Card title="Organization Management" icon="building" href="/product/enterprise-offering/org-management">
Teams, projects, and role-based access
</Card>

<Card title="Audit Logs" icon="shield-check" href="/product/enterprise-offering/access-control-management#audit-logs">
Compliance and audit logging
</Card>
</CardGroup>

### Reliability
<CardGroup cols={3}>
  <Card title="Fallbacks" icon="life-ring" href="/product/ai-gateway/fallbacks">
    Auto-switch on provider failures
  </Card>
  <Card title="Conditional Routing" icon="route" href="/product/ai-gateway/conditional-routing">
    Route based on complexity or language
  </Card>
  <Card title="Load Balancing" icon="balance-scale" href="/product/ai-gateway/load-balancing">
    Distribute across providers
  </Card>
  <Card title="Caching" icon="database" href="/product/ai-gateway/cache-simple-and-semantic">
    Cache common patterns
  </Card>
  <Card title="Smart Retries" icon="refresh" href="/product/ai-gateway/automatic-retries">
    Automatic retry with backoff
  </Card>
  <Card title="Budget Limits" icon="shield-check" href="/product/ai-gateway/virtual-keys/budget-limits">
    Enforce spending limits
  </Card>
</CardGroup>

### Security Guardrails

Protect your data:
- Prevent sensitive data leaks
- PII detection and masking
- Content filtering
- Custom security rules

<Card title="Guardrails" icon="shield-check" href="/product/guardrails">
</Card>

# FAQs
<AccordionGroup>

<Accordion title="How do I update budget limits?">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) → click your provider → update limits → save.
</Accordion>

<Accordion title="Can I use multiple providers with one API key?">
Yes. Create a config with multiple providers and attach it to your API key.
</Accordion>

<Accordion title="How do I track costs per team?">
Options:
- Create separate providers for each team
- Use metadata tags in requests
- Set up team-specific API keys
- Filter in the analytics dashboard
</Accordion>

<Accordion title="What happens when a team exceeds their budget?">
Requests are blocked until limits are adjusted. Admins receive notifications.
</Accordion>

</AccordionGroup>

# Next Steps

**Join our Community**
- [Discord Community](https://portkey.sh/discord-report)
- [GitHub Repository](https://github.com/Portkey-AI)

<Note>
For enterprise support and custom features, contact our [enterprise team](https://calendly.com/portkey-ai).
</Note>
