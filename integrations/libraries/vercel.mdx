---
title: 'Vercel AI SDK'
description: 'Add observability, reliability, and cost control to Vercel AI apps.'
---

Portkey integrates natively with the Vercel AI SDK to add production features:

- Full observability (costs, latency, logs)
- Access to 250+ LLMs through one interface
- Automatic fallbacks, retries, and caching
- Budget controls and guardrails

## Quick Start

```typescript
import { createPortkey } from '@portkey-ai/vercel-provider';
import { generateText } from 'ai';

const portkey = createPortkey({
  apiKey: 'PORTKEY_API_KEY'
});

const { text } = await generateText({
  model: portkey.chatModel('@openai-prod/gpt-4o'),
  prompt: 'What is Portkey?'
});

console.log(text);
```

All requests now route through Portkey with full observability.

## Setup

### 1. Install Package

```sh
npm install @portkey-ai/vercel-provider
```

### 2. Add Provider in Model Catalog

1. Go to [**Model Catalog → Add Provider**](https://app.portkey.ai/model-catalog/providers)
2. Select your provider (OpenAI, Anthropic, Google, etc.)
3. Enter your API keys
4. Name your provider (e.g., `openai-prod`)

Your provider slug is **`@openai-prod`** (or whatever you named it).

<Card title="Model Catalog Guide →" href="/product/model-catalog">
  Set up budgets, rate limits, and manage credentials
</Card>

### 3. Get Portkey API Key

Create your API key at [app.portkey.ai/api-keys](https://app.portkey.ai/api-keys).

**Pro tip:** Attach a default config to your API key for features like fallbacks and caching—no code changes needed.

### 4. Use in Code

```typescript
import { createPortkey } from '@portkey-ai/vercel-provider';

const portkey = createPortkey({
  apiKey: 'PORTKEY_API_KEY'
});

// Use provider slug + model name
const response = await generateText({
  model: portkey.chatModel('@openai-prod/gpt-4o'),
  prompt: 'Hello!'
});
```

## Vercel Functions

Works with all Vercel AI functions:

<CodeGroup>

```typescript generateText
import { createPortkey } from '@portkey-ai/vercel-provider';
import { generateText } from 'ai';

const portkey = createPortkey({ apiKey: 'PORTKEY_API_KEY' });

const { text } = await generateText({
  model: portkey.chatModel('@openai-prod/gpt-4o'),
  prompt: 'What is Portkey?'
});

console.log(text);
```

```typescript streamText
import { createPortkey } from '@portkey-ai/vercel-provider';
import { streamText } from 'ai';

const portkey = createPortkey({ apiKey: 'PORTKEY_API_KEY' });

const result = await streamText({
  model: portkey.chatModel('@openai-prod/gpt-4o'),
  prompt: 'Invent a new holiday and describe its traditions.'
});

for await (const chunk of result.textStream) {
  process.stdout.write(chunk);
}
```

</CodeGroup>

### Tool Calling

```typescript
import { createPortkey } from '@portkey-ai/vercel-provider';
import { generateText, tool } from 'ai';
import { z } from 'zod';

const portkey = createPortkey({ apiKey: 'PORTKEY_API_KEY' });

const result = await generateText({
  model: portkey.chatModel('@openai-prod/gpt-4o'),
  tools: {
    weather: tool({
      description: 'Get the weather in a location',
      parameters: z.object({
        location: z.string().describe('The location to get the weather for')
      }),
      execute: async ({ location }) => ({
        location,
        temperature: 72 + Math.floor(Math.random() * 21) - 10
      })
    })
  },
  prompt: 'What is the weather in San Francisco?'
});
```

## Switching Providers

Change the model string to switch providers:

```typescript
// OpenAI
portkey.chatModel('@openai-prod/gpt-4o')

// Anthropic
portkey.chatModel('@anthropic-prod/claude-sonnet-4')

// Google
portkey.chatModel('@google-prod/gemini-2.0-flash')
```

No other code changes needed.

## Advanced Features

For fallbacks, caching, and load balancing, create a [Config](https://app.portkey.ai/configs) and attach it to your API key. The config applies automatically—no code changes required.

### Fallbacks

Auto-switch to backup models if the primary fails:

```json
{
  "strategy": { "mode": "fallback" },
  "targets": [
    { "override_params": { "model": "@openai-prod/gpt-4o" } },
    { "override_params": { "model": "@anthropic-prod/claude-sonnet-4" } }
  ]
}
```

### Load Balancing

Distribute requests across providers:

```json
{
  "strategy": { "mode": "loadbalance" },
	"targets": [
    { "override_params": { "model": "@openai-prod/gpt-4o" }, "weight": 0.7 },
    { "override_params": { "model": "@anthropic-prod/claude-sonnet-4" }, "weight": 0.3 }
	]
}
```

### Caching

Reduce costs with response caching:

```json
{
  "cache": { "mode": "semantic" },
  "override_params": { "model": "@openai-prod/gpt-4o" }
}
```

### Runtime Config

Pass config inline when needed:

```typescript
const portkey = createPortkey({
  apiKey: 'PORTKEY_API_KEY',
  config: {
    strategy: { mode: 'fallback' },
    targets: [
      { override_params: { model: '@openai-prod/gpt-4o' } },
      { override_params: { model: '@anthropic-prod/claude-sonnet-4' } }
    ]
  }
});

// Model comes from config, so pass empty string
const { text } = await generateText({
  model: portkey.chatModel(''),
  prompt: 'What is Portkey?'
});
```

<Card title="Configs Guide →" href="/product/ai-gateway/configs">
  Fallbacks, retries, caching, load balancing, and more
</Card>

## Guardrails

Add input/output validation via config:

```json
		{
  "input_guardrails": ["guardrail-id-xxx"],
  "output_guardrails": ["guardrail-id-yyy"],
  "override_params": { "model": "@openai-prod/gpt-4o" }
}
```

<Card title="Guardrails Guide →" href="/product/guardrails">
  PII detection, content filtering, and custom rules
</Card>

## Observability

All requests are automatically logged with:
- Cost and token usage
- Latency metrics
- Full request/response payloads
- Custom metadata

<Frame>
  <img src="/images/product/dashboard.png" alt="Portkey Dashboard" />
</Frame>

<Card title="Observability Guide →" href="/product/observability">
  Track costs, performance, and debug issues
</Card>

## Next Steps

<CardGroup cols={2}>
  <Card title="Model Catalog" icon="database" href="/product/model-catalog">
    Set up providers and budgets
  </Card>
  <Card title="Configs" icon="gear" href="/product/ai-gateway/configs">
    Configure fallbacks and routing
  </Card>
  <Card title="Observability" icon="chart-line" href="/product/observability">
    Track costs and performance
  </Card>
  <Card title="Guardrails" icon="shield" href="/product/guardrails">
    Add PII detection and filtering
  </Card>
</CardGroup>
