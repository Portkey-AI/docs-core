---
title: 'n8n'
description: 'Add observability, cost controls, and security guardrails to your n8n workflows'
---

n8n is a workflow automation platform. Portkey adds enterprise controls for production deployments:

- **1600+ LLMs** — Single interface for all providers, not just OpenAI & Anthropic
- **Observability** — Real-time tracking for 40+ metrics and logs
- **Governance** — Budget limits, rate limits, and RBAC
- **Guardrails** — PII detection, content filtering, compliance controls

<Note>
For enterprise governance setup, see [Enterprise Governance](#enterprise-governance).
</Note>

## Quick Start

### 1. Setup Portkey

<Steps>
<Step title="Add Provider">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) → **Add Provider**.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" width="500"/>
</Frame>
</Step>

<Step title="Configure Credentials">
Select your provider (OpenAI, Anthropic, etc.), enter your API key, and create a slug like `openai-prod`.

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>
</Step>

<Step title="Create Config">
Go to [Configs](https://app.portkey.ai/configs) and create:

```json
{
  "override_params": {
    "model": "@openai-prod/gpt-4o"
  }
}
```

Save and note the Config ID.

<Frame>
<img src="/images/product/model-catalog/default-config-model-catalog.png" width="600"/>
</Frame>
</Step>

<Step title="Get Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) → Create new key → Attach your config → Save.

<Frame>
<img src="/images/integrations/api-key.png" width="300"/>
</Frame>
</Step>
</Steps>

### 2. Configure n8n

1. Add the **OpenAI** node to your workflow
2. Configure credentials:
   - **API Key**: Your Portkey API key
   - **Base URL**: `https://api.portkey.ai/v1`

<Frame>
<img src="/images/integrations/n8n-2.webp" width="500"/>
</Frame>

3. Configure the OpenAI node with your model. The model in your config will override the default.

<Frame>
<img src="/images/integrations/n8n-1.webp" width="500"/>
</Frame>

Done! Monitor requests in the [Portkey Dashboard](https://app.portkey.ai/dashboard).

---

## Enterprise Governance

For organizations using n8n, Portkey adds governance controls:

<AccordionGroup>
<Accordion title="Budget & Rate Limits">
Create providers with spending limits per team:

1. Go to [Model Catalog](https://app.portkey.ai/model-catalog)
2. Create provider for each team with budget/rate limits

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>
</Accordion>

<Accordion title="Model Access Rules">
Control which models teams can access at the integration level.

<Frame>
<img src="/images/product/model-catalog/model-provisioning-page.png" width="500"/>
</Frame>
</Accordion>

<Accordion title="Routing Configuration">
Use Configs for fallbacks, load balancing, caching:

```json
{
  "strategy": { "mode": "loadbalance" },
  "targets": [
    { "override_params": { "model": "@openai-prod/gpt-4o" } },
    { "override_params": { "model": "@anthropic-prod/claude-sonnet-4-20250514" } }
  ]
}
```

Create configs at [app.portkey.ai/configs](https://app.portkey.ai/configs).
</Accordion>

<Accordion title="Team API Keys">
Create team-specific API keys with metadata:

```python
from portkey_ai import Portkey

portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

api_key = portkey.api_keys.create(
    name="frontend-team",
    workspace_id="YOUR_WORKSPACE_ID",
    defaults={
        "config_id": "your-config-id",
        "metadata": {"team": "frontend", "environment": "production"}
    },
    scopes=["logs.view", "configs.read"]
)
```
</Accordion>
</AccordionGroup>

---

## Features

### Observability

Track 40+ metrics: cost, tokens, latency, performance. Filter by custom metadata.

<Frame>
<img src="/images/integrations/observability.png" width="600"/>
</Frame>

### Logs

Complete request/response tracking with metadata tags and cost attribution.

<Frame>
<img src="/images/llms/openai/logs.png"/>
</Frame>

### Reliability

<CardGroup cols={3}>
<Card title="Fallbacks" icon="life-ring" href="/product/ai-gateway/fallbacks">
Auto-switch on failure
</Card>
<Card title="Load Balancing" icon="balance-scale" href="/product/ai-gateway/load-balancing">
Distribute across providers
</Card>
<Card title="Caching" icon="database" href="/product/ai-gateway/cache-simple-and-semantic">
Reduce costs and latency
</Card>
<Card title="Retries" icon="rotate" href="/product/ai-gateway/automatic-retries">
Exponential backoff
</Card>
<Card title="Conditional Routing" icon="route" href="/product/ai-gateway/conditional-routing">
Route by conditions
</Card>
<Card title="Budget Limits" icon="coins" href="/product/model-catalog/integrations#3-budget-%26-rate-limits">
Control spending
</Card>
</CardGroup>

### Guardrails

Protect workflows with real-time checks:
- PII detection and masking
- Content filtering
- Custom security rules

<Card title="Guardrails" icon="shield-check" href="/product/guardrails">
Configure input/output protection
</Card>

---

## FAQs

<AccordionGroup>
<Accordion title="Can I use multiple providers with one API key?">
Yes. Create multiple providers and attach them to a single config. The config connects to your API key.
</Accordion>

<Accordion title="How do I track costs per team?">
Create separate providers per team, use metadata tags, or set up team-specific API keys.
</Accordion>

<Accordion title="What happens when budget limit is reached?">
Requests are blocked. Admins get notified. Limits can be adjusted anytime.
</Accordion>
</AccordionGroup>

---

## Next Steps

<CardGroup cols={2}>
<Card title="Model Catalog" icon="list" href="/product/model-catalog">
Set up providers and budgets
</Card>
<Card title="Configs" icon="gear" href="/product/ai-gateway/configs">
Configure routing and reliability
</Card>
</CardGroup>

**Community:** [Discord](https://portkey.sh/discord-report) · [GitHub](https://github.com/Portkey-AI)
