---
title: 'LibreChat'
description: 'Cost tracking, observability, and more for LibreChat'
---

Add Portkey to LibreChat to get:
- **Unified access to 1600+ LLMs** through a single API
- **Real-time observability** with 40+ metrics and detailed logs
- **Enterprise governance** with budget limits and RBAC
- **Security guardrails** for PII detection and content filtering

<Note>
For enterprise governance setup, see [Enterprise Governance](#3-enterprise-governance).
</Note>

## 1. Setup Portkey

<Steps>
<Step title="Add Provider">
Go to [Model Catalog → AI Providers](https://app.portkey.ai/model-catalog) and add your provider (OpenAI, Anthropic, etc.) with your API credentials.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" alt="Add Provider" />
</Frame>
</Step>

<Step title="Create Config (Optional)">
Go to [Configs](https://app.portkey.ai/configs) and create a config for routing, fallbacks, or other features:

```json
{"override_params": {"model": "@openai-prod/gpt-4o"}}
```

<Frame>
<img src="/images/integrations/config.png" width="500"/>
</Frame>
</Step>

<Step title="Create Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) → **Create New API Key**. Optionally attach your config from Step 2.

<Frame>
<img src="/images/integrations/api-key.png" width="500"/>
</Frame>
</Step>
</Steps>


## 2. Integrate with LibreChat

### Configure Files

**docker-compose.override.yml** ([docs](https://www.librechat.ai/docs/quick_start/custom_endpoints))

```yaml docker-compose.override.yml
services:
  api:
    volumes:
    - type: bind
      source: ./librechat.yaml
      target: /app/librechat.yaml
```

**.env**

```env .env
PORTKEY_API_KEY=YOUR_PORTKEY_API_KEY
PORTKEY_GATEWAY_URL=https://api.portkey.ai/v1
```

**librechat.yaml** - Choose one option:

<CodeGroup>
```yaml With Config
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-config: "pc-libre-xxx"
      models:
        default: ["@openai-prod/gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      modelDisplayLabel: "Portkey"
```

```yaml With Provider Slug
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-provider: "@openai-prod"
      models:
        default: ["gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      modelDisplayLabel: "Portkey:OpenAI"
```
</CodeGroup>

<Note>
LibreChat requires an `apiKey` field—use `"dummy"` since auth is via Portkey headers.
</Note>

<Note>
For per-user cost tracking in centralized deployments, see [this community guide](https://github.com/timmanik/librechat-for-portkey).
</Note>


import AdvancedFeatures from '/snippets/portkey-advanced-features.mdx';

<AdvancedFeatures />