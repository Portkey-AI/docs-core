---
title: 'LibreChat'
description: 'Cost tracking, observability, and more for LibreChat'
---

Add Portkey to LibreChat to get:
- **Unified access to 1600+ LLMs** through a single API
- **Real-time observability** with 40+ metrics and detailed logs
- **Enterprise governance** with budget limits and RBAC
- **Security guardrails** for PII detection and content filtering

<Note>
For enterprise governance setup, see [Enterprise Governance](#3-enterprise-governance).
</Note>

## 1. Setup Portkey

<Steps>
<Step title="Add Provider">
Go to [Model Catalog → AI Providers](https://app.portkey.ai/model-catalog) and add your provider (OpenAI, Anthropic, etc.) with your API credentials.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" alt="Add Provider" />
</Frame>
</Step>

<Step title="Create Config (Optional)">
Go to [Configs](https://app.portkey.ai/configs) and create a config for routing, fallbacks, or other features:

```json
{"override_params": {"model": "@openai-prod/gpt-4o"}}
```

<Frame>
<img src="/images/integrations/config.png" width="500"/>
</Frame>
</Step>

<Step title="Create Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) → **Create New API Key**. Optionally attach your config from Step 2.

<Frame>
<img src="/images/integrations/api-key.png" width="500"/>
</Frame>
</Step>
</Steps>


## 2. Integrate with LibreChat

### Configure Files

**docker-compose.override.yml** ([docs](https://www.librechat.ai/docs/quick_start/custom_endpoints))

```yaml docker-compose.override.yml
services:
  api:
    volumes:
    - type: bind
      source: ./librechat.yaml
      target: /app/librechat.yaml
```

**.env**

```env .env
PORTKEY_API_KEY=YOUR_PORTKEY_API_KEY
PORTKEY_GATEWAY_URL=https://api.portkey.ai/v1
```

**librechat.yaml** - Choose one option:

<CodeGroup>
```yaml With Config
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-config: "pc-libre-xxx"
      models:
        default: ["@openai-prod/gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      modelDisplayLabel: "Portkey"
```

```yaml With Provider Slug
version: 1.1.4
cache: true
endpoints:
  custom:
    - name: "Portkey"
      apiKey: "dummy"
      baseURL: ${PORTKEY_GATEWAY_URL}
      headers:
        x-portkey-api-key: "${PORTKEY_API_KEY}"
        x-portkey-provider: "@openai-prod"
      models:
        default: ["gpt-4o"]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      modelDisplayLabel: "Portkey:OpenAI"
```
</CodeGroup>

<Note>
LibreChat requires an `apiKey` field—use `"dummy"` since auth is via Portkey headers.
</Note>

<Note>
For per-user cost tracking in centralized deployments, see [this community guide](https://github.com/timmanik/librechat-for-portkey).
</Note>


# 3. Enterprise Governance

<AccordionGroup>
  <Accordion title="Budget Controls & Rate Limits">
    Create providers per team with [budget & rate limits](/product/model-catalog/integrations#3-budget-%26-rate-limits) in [Model Catalog](https://app.portkey.ai/model-catalog).
    <Frame>
      <img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
    </Frame>
  </Accordion>

  <Accordion title="Model Access Rules">
    Use Model Catalog to provision which models are exposed to each workspace.

```json
{"strategy": {"mode": "single"}, "targets": [{"override_params": {"model": "@openai-prod/gpt-4o"}}]}
```

    Create configs in [Configs](https://app.portkey.ai/configs). Update anytime without redeploying.
  </Accordion>

  <Accordion title="Team-Specific API Keys">
    Create API keys with metadata for tracking and scoped permissions:

```python
from portkey_ai import Portkey

portkey = Portkey(api_key="YOUR_ADMIN_API_KEY")

api_key = portkey.api_keys.create(
    name="engineering-team",
    type="organisation",
    workspace_id="YOUR_WORKSPACE_ID",
    defaults={
        "config_id": "your-config-id",
        "metadata": {"environment": "production", "department": "engineering"}
    },
    scopes=["logs.view", "configs.read"]
)
```
  </Accordion>

  <Accordion title="Deploy & Monitor">
    Distribute API keys and monitor in Portkey dashboard: cost tracking, model usage patterns, request volumes, error rates.
  </Accordion>
</AccordionGroup>

# Portkey Features

<CardGroup cols={2}>
  <Card title="Observability" icon="chart-line" href="/product/observability">
    Track 40+ metrics: cost, tokens, latency. Filter by custom metadata.
  </Card>
  <Card title="1600+ LLMs" icon="layer-group" href="/integrations/llms">
    Switch providers by changing the model slug in your config.
  </Card>
  <Card title="Guardrails" icon="shield-check" href="/product/guardrails">
    PII detection, content filtering, compliance controls.
  </Card>
  <Card title="Custom Metadata" icon="tags" href="/product/observability/metadata">
    Filter logs, track usage, attribute costs by team.
  </Card>
</CardGroup>

### Reliability

<CardGroup cols={3}>
  <Card title="Fallbacks" icon="life-ring" href="/product/ai-gateway/fallbacks">
    Auto-switch to backup on failure.
  </Card>
  <Card title="Load Balancing" icon="scale-balanced" href="/product/ai-gateway/load-balancing">
    Distribute requests by weight.
  </Card>
  <Card title="Caching" icon="database" href="/product/ai-gateway/cache-simple-and-semantic">
    Reduce costs with response caching.
  </Card>
  <Card title="Retries" icon="rotate" href="/product/ai-gateway/automatic-retries">
    Exponential backoff on failures.
  </Card>
  <Card title="Conditional Routing" icon="route" href="/product/ai-gateway/conditional-routing">
    Route by metadata conditions.
  </Card>
  <Card title="Budget Limits" icon="coins" href="/product/model-catalog/integrations#3-budget-%26-rate-limits">
    Control spending per team.
  </Card>
</CardGroup>

### Enterprise

<CardGroup cols={2}>
  <Card title="SSO" icon="key" href="/product/enterprise-offering/org-management/sso">
    SAML 2.0, Okta, Azure AD support.
  </Card>
  <Card title="Organization Management" icon="building" href="/product/enterprise-offering/org-management">
    Workspaces, teams, RBAC.
  </Card>
  <Card title="Audit Logs" icon="shield-check" href="/product/enterprise-offering/access-control-management#audit-logs">
    Access control and compliance tracking.
  </Card>
  <Card title="Budget Controls" icon="coins" href="/product/model-catalog/integrations#3-budget-%26-rate-limits">
    Granular spending limits.
  </Card>
</CardGroup>


# FAQs

<AccordionGroup>
  <Accordion title="Can I use multiple LLM providers with the same API key?">
    Yes. Create multiple providers in Model Catalog, add them to a single config, and attach that config to your API key.
  </Accordion>
  <Accordion title="How do I track costs for different teams?">
    Create separate providers per team, use metadata tags in configs, or set up team-specific API keys. Monitor in the analytics dashboard.
  </Accordion>
  <Accordion title="What happens if a team exceeds their budget limit?">
    Requests are blocked, admins notified, usage stats remain visible. Adjust limits as needed.
  </Accordion>
</AccordionGroup>

# Next Steps

- [Discord Community](https://portkey.sh/discord-report)
- [GitHub Repository](https://github.com/Portkey-AI)

<Note>
For enterprise support, contact our [enterprise team](https://calendly.com/portkey-ai).
</Note>
