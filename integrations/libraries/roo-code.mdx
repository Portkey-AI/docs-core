---
title: 'Roo Code'
description: 'Add enterprise-grade observability, cost tracking, and governance to your Roo AI coding assistant'
---

Roo is an AI coding assistant for VS Code. Add Portkey to get:

- **1600+ LLMs** through one interface - switch providers instantly
- **Observability** - track costs, tokens, and latency for every request
- **Reliability** - automatic fallbacks, retries, and caching
- **Governance** - budget limits, usage tracking, and team access controls

This guide shows how to configure Roo with Portkey in under 5 minutes.

<Note>
  For enterprise deployments across teams, see [Enterprise Governance](#3-enterprise-governance).
</Note>

# 1. Setup

<Steps>
<Step title="Add Provider">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) → **Add Provider**.

<Frame>
<img src="/Screenshot2025-07-21at5.29.57PM.png" width="500"/>
</Frame>
</Step>

<Step title="Configure Credentials">
Select your provider (OpenAI, Anthropic, etc.), enter your API key, and create a slug like `openai-prod`.

<Frame>
<img src="/images/product/model-catalog/create-provider-page.png" width="500"/>
</Frame>
</Step>

<Step title="Get Portkey API Key">
Go to [API Keys](https://app.portkey.ai/api-keys) and generate your Portkey API key.
</Step>
</Steps>


# 2. Integrate Portkey with Roo

Now that you have your Portkey components set up, let's connect them to Roo. Since Portkey provides OpenAI API compatibility, integration is straightforward and requires just a few configuration steps in your VS Code settings.

<Note>
You need your Portkey API Key from [Step 1](#1-setting-up-portkey) before going further.
</Note>

# 2. Configure Roo

<Steps>
<Step title="Open Settings">
In VS Code:
1. Click the Roo icon in the activity bar
2. Click the settings gear icon ⚙️
</Step>

<Step title="Add Portkey Configuration">
In Providers, enter:

- **API Provider**: `OpenAI Compatible`
- **Base URL**: `https://api.portkey.ai/v1`
- **OpenAI API Key**: Your Portkey API key
- **Model**: `@openai-prod/gpt-4o` (or your provider slug + model)
</Step>
</Steps>

Done! Monitor usage in the [Portkey Dashboard](https://app.portkey.ai/dashboard).

## Switch Providers

Change models by updating the **Model** field:

```
@anthropic-prod/claude-3-5-sonnet-20241022
@openai-prod/gpt-4o
@google-prod/gemini-2.0-flash-exp
```

All requests route through Portkey automatically.

<Note>
**Want fallbacks, load balancing, or caching?** Create a [Portkey Config](/product/ai-gateway/configs), attach it to your API key, and set Model to `dummy`. See [Enterprise Governance](#3-enterprise-governance) for examples.
</Note>



import AdvancedFeatures from '/snippets/portkey-advanced-features.mdx';

<AdvancedFeatures />