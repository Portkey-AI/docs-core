---
title: "Fine-tune"
description: "Fine-tune your models with Azure OpenAI"
---

Azure OpenAI follows a similar fine-tuning process as OpenAI, with some Azure-specific configurations. The examples below show how to use Portkey with Azure OpenAI for fine-tuning.

### Upload a file

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@PROVIDER" 
)

# Upload a file for fine-tuning
file = portkey.files.create(
    file="dataset.jsonl",
    purpose="fine-tune"
)

print(file)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";
import * as fs from 'fs';

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@PROVIDER"    for Azure OpenAI
});

(async () => {
    // Upload a file for fine-tuning
    const file = await portkey.files.create({
        file: fs.createReadStream("dataset.jsonl"),
        purpose: "fine-tune"
    });

    console.log(file);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import AzureOpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = AzureOpenAI(
    api_key="AZURE_OPENAI_API_KEY",
    api_version="2023-05-15",
    azure_endpoint=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# Upload a file for fine-tuning
file = client.files.create(
    file=open("dataset.jsonl", "rb"),
    purpose="fine-tune"
)

print(file)
```
</Tab>
<Tab title="REST API">
```sh
curl -X POST --header 'x-portkey-api-key: <portkey_api_key>' \
 --header 'x-portkey-provider: @provider' \
 --form 'file=@dataset.jsonl' \
 --form 'purpose=fine-tune' \
 'https://api.portkey.ai/v1/files'
```
</Tab>
</Tabs>

### Create a fine-tuning job

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@PROVIDER" 
)

# Create a fine-tuning job
fine_tune_job = portkey.fine_tuning.jobs.create(
    model="gpt-35-turbo", # Base model to fine-tune
    training_file="file_id", # ID of the uploaded training file
    validation_file="file_id", # Optional: ID of the uploaded validation file
    suffix="finetune_name", # Custom suffix for the fine-tuned model name
    hyperparameters={
        "n_epochs": 1
    }
)

print(fine_tune_job)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@PROVIDER"    for Azure OpenAI
});

(async () => {
    // Create a fine-tuning job
    const fineTuneJob = await portkey.fineTuning.jobs.create({
        model: "gpt-35-turbo", // Base model to fine-tune
        training_file: "file_id", // ID of the uploaded training file
        validation_file: "file_id", // Optional: ID of the uploaded validation file
        suffix: "finetune_name", // Custom suffix for the fine-tuned model name
        hyperparameters: {
            n_epochs: 1
        }
    });

    console.log(fineTuneJob);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import AzureOpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

client = AzureOpenAI(
    api_key="AZURE_OPENAI_API_KEY",
    api_version="2023-05-15",
    azure_endpoint=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# Create a fine-tuning job
fine_tune_job = client.fine_tuning.jobs.create(
    model="gpt-35-turbo", # Base model to fine-tune
    training_file="file_id", # ID of the uploaded training file
    validation_file="file_id", # Optional: ID of the uploaded validation file
    suffix="finetune_name", # Custom suffix for the fine-tuned model name
    hyperparameters={
        "n_epochs": 1
    }
)

print(fine_tune_job)
```
</Tab>
<Tab title="REST API">
```sh
curl -X POST --header 'Content-Type: application/json' \
 --header 'x-portkey-api-key: <portkey_api_key>' \
 --header 'x-portkey-provider: @provider' \
 --data \
 $'{"model": "<base_model>", "suffix": "<finetune_name>", "training_file": "<file_id>", "validation_file": "<file_id>", "hyperparameters": {"n_epochs": 1}}\n' \
'https://api.portkey.ai/v1/fine_tuning/jobs'
```
</Tab>
</Tabs>

For more detailed examples and other fine-tuning operations (listing jobs, retrieving job details, canceling jobs, and getting job events), please refer to the [OpenAI fine-tuning documentation](/integrations/llms/openai/fine-tuning).

The Azure OpenAI fine-tuning API documentation is available at [Azure OpenAI API](https://learn.microsoft.com/en-us/rest/api/azureopenai/fine-tuning/create?view=rest-azureopenai-2025-01-01-preview&tabs=HTTP).