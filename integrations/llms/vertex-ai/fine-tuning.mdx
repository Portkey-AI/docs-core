---
title: "Fine-tune"
description: "Fine-tune your models with Vertex AI"
---

### Upload a file

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@VERTEX_PROVIDER", 
    vertex_storage_bucket_name="your_bucket_name", # Specify the GCS bucket name
    provider_file_name="your_file_name.jsonl", # Specify the file name in GCS
    provider_model="gemini-1.5-flash-001" # Specify the model to fine-tune
)

# Upload a file for fine-tuning
file = portkey.files.create(
    file=open("dataset.jsonl", "rb"),
    purpose="fine-tune"
)

print(file)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";
import * as fs from 'fs';

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@VERTEX_PROVIDER",   
    vertexStorageBucketName: "your_bucket_name", // Specify the GCS bucket name
    providerFileName: "your_file_name.jsonl", // Specify the file name in GCS
    providerModel: "gemini-1.5-flash-001" // Specify the model to fine-tune
});

(async () => {
    // Upload a file for fine-tuning
    const file = await portkey.files.create({
        file: fs.createReadStream("dataset.jsonl"),
        purpose: "fine-tune"
    });

    console.log(file);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

openai = OpenAI(
    api_key='OPENAI_API_KEY',
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@VERTEX_PROVIDER",
        api_key="PORTKEY_API_KEY",
        vertex_storage_bucket_name="your_bucket_name",
        provider_file_name="your_file_name.jsonl",
        provider_model="gemini-1.5-flash-001"
    )
)

# Upload a file for fine-tuning
file = openai.files.create(
    file=open("dataset.jsonl", "rb"),
    purpose="fine-tune"
)

print(file)
```
</Tab>
<Tab title="OpenAI NodeJS">
```typescript
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';
import * as fs from 'fs';

const openai = new OpenAI({
    apiKey: 'OPENAI_API_KEY',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        provider:"@VERTEX_PROVIDER",
        apiKey: "PORTKEY_API_KEY",
        vertexStorageBucketName: "your_bucket_name",
        providerFileName: "your_file_name.jsonl",
        providerModel: "gemini-1.5-flash-001"
    })
});

(async () => {
    // Upload a file for fine-tuning
    const file = await openai.files.create({
        file: fs.createReadStream("dataset.jsonl"),
        purpose: "fine-tune"
    });

    console.log(file);
})();
```
</Tab>
<Tab title="REST API">
```sh
curl -X POST --header 'x-portkey-api-key: <portkey_api_key>' \
 --header 'x-portkey-provider: <vertex_virtual_key>' \
 --header 'x-portkey-vertex-storage-bucket-name: <bucket_name>' \
 --header 'x-portkey-provider-file-name: <file_name>.jsonl' \
 --header 'x-portkey-provider-model: <model_name>' \
 --form 'purpose="fine-tune"' \
 --form 'file=@dataset.jsonl' \
 'https://api.portkey.ai/v1/files'
```
</Tab>
</Tabs>

### Create a fine-tuning job

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@VERTEX_PROVIDER" 
)

# Create a fine-tuning job
fine_tune_job = portkey.fine_tuning.jobs.create(
    model="gemini-1.5-pro-002", # Base model to fine-tune
    training_file="<file_id>", # Encoded GCS path to the training file 
    suffix="finetune_name", # Custom suffix for the fine-tuned model name
    hyperparameters={
        "n_epochs": 2
    }
)

print(fine_tune_job)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@VERTEX_PROVIDER"   
});

(async () => {
    // Create a fine-tuning job
    const fineTuneJob = await portkey.fineTuning.jobs.create({
        model: "gemini-1.5-pro-002", // Base model to fine-tune
        training_file: "<file_id>", // Encoded GCS path to the training file 
        suffix: "finetune_name", // Custom suffix for the fine-tuned model name
        hyperparameters: {
            n_epochs: 2
        }
    });

    console.log(fineTuneJob);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

openai = OpenAI(
    api_key='OPENAI_API_KEY',
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@VERTEX_PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# Create a fine-tuning job
fine_tune_job = openai.fine_tuning.jobs.create(
    model="gemini-1.5-pro-002", # Base model to fine-tune
    training_file="<file_id>", # Encoded GCS path to the training file 
    suffix="finetune_name", # Custom suffix for the fine-tuned model name
    hyperparameters={
        "n_epochs": 2
    }
)

print(fine_tune_job)
```
</Tab>
<Tab title="OpenAI NodeJS">
```typescript
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const openai = new OpenAI({
    apiKey: 'OPENAI_API_KEY',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        provider:"@VERTEX_PROVIDER",
        apiKey: "PORTKEY_API_KEY"
    })
});

(async () => {
    // Create a fine-tuning job
    const fineTuneJob = await openai.fineTuning.jobs.create({
        model: "gemini-1.5-pro-002", // Base model to fine-tune
        training_file: "<file_id>", // Encoded GCS path to the training file 
        suffix: "finetune_name", // Custom suffix for the fine-tuned model name
        hyperparameters: {
            n_epochs: 2
        }
    });

    console.log(fineTuneJob);
})();
```
</Tab>
<Tab title="REST API">
```sh
curl -X POST --header 'Content-Type: application/json' \
 --header 'x-portkey-api-key: <portkey_api_key>' \
 --header 'x-portkey-provider: <vertex_virtual_key>' \
 --data \
 $'{"model": "<base_model>", "suffix": "<finetune_name>", "training_file": "gs://<bucket_name>/<file_name>.jsonl", "hyperparameters": {"n_epochs": 2}}\n' \
'https://api.portkey.ai/v1/fine_tuning/jobs'
```
</Tab>
</Tabs>

### List fine-tuning jobs

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@VERTEX_PROVIDER" 
)

# List all fine-tuning jobs
jobs = portkey.fine_tuning.jobs.list(
    limit=10  # Optional: Number of jobs to retrieve (default: 20)
)

print(jobs)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@VERTEX_PROVIDER"   
});

(async () => {
    // List all fine-tuning jobs
    const jobs = await portkey.fineTuning.jobs.list({
        limit: 10  // Optional: Number of jobs to retrieve (default: 20)
    });

    console.log(jobs);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

openai = OpenAI(
    api_key='OPENAI_API_KEY',
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@VERTEX_PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# List all fine-tuning jobs
jobs = openai.fine_tuning.jobs.list(
    limit=10  # Optional: Number of jobs to retrieve (default: 20)
)

print(jobs)
```
</Tab>
<Tab title="OpenAI NodeJS">
```typescript
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const openai = new OpenAI({
    apiKey: 'OPENAI_API_KEY',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        provider:"@VERTEX_PROVIDER",
        apiKey: "PORTKEY_API_KEY"
    })
});

(async () => {
    // List all fine-tuning jobs
    const jobs = await openai.fineTuning.jobs.list({
        limit: 10  // Optional: Number of jobs to retrieve (default: 20)
    });

    console.log(jobs);
})();
```
</Tab>
<Tab title="REST API">
```sh
curl -X GET --header 'x-portkey-api-key: <portkey_api_key>' \
--header 'x-portkey-provider: <vertex_virtual_key>' \
'https://api.portkey.ai/v1/fine_tuning/jobs'
```
</Tab>
</Tabs>

### Get a fine-tuning job

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@VERTEX_PROVIDER" 
)

# Retrieve a specific fine-tuning job
job = portkey.fine_tuning.jobs.retrieve(
    "job_id"  # The ID of the fine-tuning job to retrieve
)

print(job)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@VERTEX_PROVIDER"   
});

(async () => {
    // Retrieve a specific fine-tuning job
    const job = await portkey.fineTuning.jobs.retrieve(
        "job_id"  // The ID of the fine-tuning job to retrieve
    );

    console.log(job);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

openai = OpenAI(
    api_key='OPENAI_API_KEY',
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@VERTEX_PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# Retrieve a specific fine-tuning job
job = openai.fine_tuning.jobs.retrieve(
    "job_id"  // The ID of the fine-tuning job to retrieve
)

print(job)
```
</Tab>
<Tab title="OpenAI NodeJS">
```typescript
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const openai = new OpenAI({
    apiKey: 'OPENAI_API_KEY',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        provider:"@VERTEX_PROVIDER",
        apiKey: "PORTKEY_API_KEY"
    })
});

(async () => {
    // Retrieve a specific fine-tuning job
    const job = await openai.fineTuning.jobs.retrieve(
        "job_id"  // The ID of the fine-tuning job to retrieve
    );

    console.log(job);
})();
```
</Tab>
<Tab title="REST API">
```sh
curl -X GET --header 'x-portkey-api-key: <portkey_api_key>' \
--header 'x-portkey-provider: <vertex_virtual_key>' \
'https://api.portkey.ai/v1/fine_tuning/jobs/<job_id>'
```
</Tab>
</Tabs>

### Cancel a fine-tuning job

<Tabs>
<Tab title="Python">
```python
from portkey_ai import Portkey

# Initialize the Portkey client
portkey = Portkey(
    api_key="PORTKEY_API_KEY", # Replace with your Portkey API key
    provider="@VERTEX_PROVIDER" 
)

# Cancel a fine-tuning job
cancelled_job = portkey.fine_tuning.jobs.cancel(
    "job_id"  # The ID of the fine-tuning job to cancel
)

print(cancelled_job)
```
</Tab>
<Tab title="NodeJS">
```typescript
import { Portkey } from "portkey-ai";

// Initialize the Portkey client
const portkey = Portkey({
    apiKey: "PORTKEY_API_KEY",  // Replace with your Portkey API key
    provider:"@VERTEX_PROVIDER"   
});

(async () => {
    // Cancel a fine-tuning job
    const cancelledJob = await portkey.fineTuning.jobs.cancel(
        "job_id"  // The ID of the fine-tuning job to cancel
    );

    console.log(cancelledJob);
})();
```
</Tab>
<Tab title="OpenAI Python">
```python
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

openai = OpenAI(
    api_key='OPENAI_API_KEY',
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        provider="@VERTEX_PROVIDER",
        api_key="PORTKEY_API_KEY"
    )
)

# Cancel a fine-tuning job
cancelled_job = openai.fine_tuning.jobs.cancel(
    "job_id"  // The ID of the fine-tuning job to cancel
)

print(cancelled_job)
```
</Tab>
<Tab title="OpenAI NodeJS">
```typescript
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const openai = new OpenAI({
    apiKey: 'OPENAI_API_KEY',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        provider:"@VERTEX_PROVIDER",
        apiKey: "PORTKEY_API_KEY"
    })
});

(async () => {
    // Cancel a fine-tuning job
    const cancelledJob = await openai.fineTuning.jobs.cancel(
        "job_id"  // The ID of the fine-tuning job to cancel
    );

    console.log(cancelledJob);
})();
```
</Tab>
<Tab title="REST API">
```sh
curl -X POST --header 'x-portkey-api-key: <portkey_api_key>' \
--header 'x-portkey-provider: <vertex_virtual_key>' \
'https://api.portkey.ai/v1/fine_tuning/jobs/<job_id>/cancel'
```
</Tab>
</Tabs>

Refer to [Google Vertex AI's fine-tuning documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) for more information on the parameters and options available.
