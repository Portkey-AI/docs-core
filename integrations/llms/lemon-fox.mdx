---
title: 'Lemonfox-AI'
description: 'Integrate LemonFox with Portkey for chat, image generation, and speech-to-text.'
---

## Quick Start

Get started with LemonFox AI in under 2 minutes:

<CodeGroup>

```python Python icon="python"
from portkey_ai import Portkey

# 1. Install: pip install portkey-ai
# 2. Add @lemonfox-ai provider in model catalog
# 3. Use it:

portkey = Portkey(api_key="PORTKEY_API_KEY")

response = portkey.chat.completions.create(
    model="@lemonfox-ai/llama-8b-chat",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```js Javascript icon="square-js"
import Portkey from 'portkey-ai'

// 1. Install: npm install portkey-ai
// 2. Add @lemonfox-ai provider in model catalog
// 3. Use it:

const portkey = new Portkey({
    apiKey: "PORTKEY_API_KEY"
})

const response = await portkey.chat.completions.create({
    model: "@lemonfox-ai/llama-8b-chat",
    messages: [{ role: "user", content: "Hello!" }]
})

console.log(response.choices[0].message.content)
```

```python OpenAI Py icon="python"
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL

# 1. Install: pip install openai portkey-ai
# 2. Add @lemonfox-ai provider in model catalog
# 3. Use it:

client = OpenAI(
    api_key="PORTKEY_API_KEY",  # Portkey API key
    base_url=PORTKEY_GATEWAY_URL
)

response = client.chat.completions.create(
    model="@lemonfox-ai/llama-8b-chat",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```js OpenAI JS icon="square-js"
import OpenAI from "openai"
import { PORTKEY_GATEWAY_URL } from "portkey-ai"

// 1. Install: npm install openai portkey-ai
// 2. Add @lemonfox-ai provider in model catalog
// 3. Use it:

const client = new OpenAI({
    apiKey: "PORTKEY_API_KEY",  // Portkey API key
    baseURL: PORTKEY_GATEWAY_URL
})

const response = await client.chat.completions.create({
    model: "@lemonfox-ai/llama-8b-chat",
    messages: [{ role: "user", content: "Hello!" }]
})

console.log(response.choices[0].message.content)
```

```sh cURL icon="square-terminal"
# 1. Add @lemonfox-ai provider in model catalog
# 2. Use it:

curl https://api.portkey.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "x-portkey-api-key: $PORTKEY_API_KEY" \
  -d '{
    "model": "@lemonfox-ai/llama-8b-chat",
    "messages": [{"role": "user", "content": "Hello!"}]
  }'
```

</CodeGroup>

## Add Provider in Model Catalog

Before making requests, add LemonFox AI to your Model Catalog:

1. Go to [**Model Catalog â†’ Add Provider**](https://app.portkey.ai/model-catalog/providers)
2. Select **LemonFox AI**
3. Enter your [LemonFox API key](https://www.lemonfox.ai/apis/keys)
4. Name your provider (e.g., `lemonfox-ai`)

<Card title="Complete Setup Guide" icon="book" href="/product/model-catalog">
  See all setup options and detailed configuration instructions
</Card>

<Card title="Lemonfox AI Documentation" icon="book" href="https://www.lemonfox.ai/apis">
  Explore the official Lemonfox AI documentation
</Card>

---

## LemonFox Capabilities

### Streaming

Stream responses for real-time output:

<CodeGroup>

```python Python
from portkey_ai import Portkey

portkey = Portkey(api_key="PORTKEY_API_KEY", provider="@lemonfox-ai")

stream = portkey.chat.completions.create(
    model="llama-8b-chat",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in stream:
    print(chunk.choices[0].delta.content or "", end="", flush=True)
```

```javascript Node.js
import Portkey from 'portkey-ai';

const portkey = new Portkey({
    apiKey: 'PORTKEY_API_KEY',
    provider: '@lemonfox-ai'
});

const stream = await portkey.chat.completions.create({
    model: 'llama-8b-chat',
    messages: [{ role: 'user', content: 'Tell me a story' }],
    stream: true
});

for await (const chunk of stream) {
    process.stdout.write(chunk.choices[0]?.delta?.content || '');
}
```

</CodeGroup>

### Image Generation

Generate images with Stable Diffusion XL:

<CodeGroup>

```python Python
from portkey_ai import Portkey

portkey = Portkey(api_key="PORTKEY_API_KEY", provider="@lemonfox-ai")

image = portkey.images.generate(
    prompt="A cute baby sea otter",
    size="1024x1024"
)

print(image.data[0].url)
```

```javascript Node.js
import Portkey from 'portkey-ai';

const portkey = new Portkey({
    apiKey: 'PORTKEY_API_KEY',
    provider: '@lemonfox-ai'
});

const image = await portkey.images.generate({
    prompt: "A cute baby sea otter",
    size: "1024x1024"
});

console.log(image.data[0].url);
```

</CodeGroup>

### Speech-to-Text

Transcribe audio with Whisper:

<CodeGroup>

```python Python
from portkey_ai import Portkey

portkey = Portkey(api_key="PORTKEY_API_KEY", provider="@lemonfox-ai")

audio_file = open("/path/to/file.mp3", "rb")

transcription = portkey.audio.transcriptions.create(
    model="whisper-1",
    file=audio_file
)

print(transcription.text)
```

```javascript Node.js
import Portkey from 'portkey-ai';
import fs from 'fs';

const portkey = new Portkey({
    apiKey: 'PORTKEY_API_KEY',
    provider: '@lemonfox-ai'
});

const transcription = await portkey.audio.transcriptions.create({
    file: fs.createReadStream("/path/to/file.mp3"),
    model: "whisper-1"
});

console.log(transcription.text);
```

</CodeGroup>

---

## Supported Endpoints and Parameters

| Endpoint | Supported Parameters |
|----------|---------------------|
| `/chat/completions` | messages, max_tokens, temperature, top_p, stream, presence_penalty, frequency_penalty |
| `/images/generations` | prompt, response_format, negative_prompt, size, n |
| `/audio/transcriptions` | translate, language, prompt, response_format, file |

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Gateway Configs" icon="sliders" href="/product/ai-gateway">
    Add fallbacks, load balancing, and more
  </Card>
  <Card title="Observability" icon="chart-line" href="/product/observability">
    Monitor and trace your LemonFox requests
  </Card>
  <Card title="Prompt Library" icon="book" href="/product/prompt-engineering-studio">
    Manage and version your prompts
  </Card>
  <Card title="Metadata" icon="tag" href="/product/observability/metadata">
    Add custom metadata to requests
  </Card>
</CardGroup>

For complete SDK documentation:

<Card title="SDK Reference" icon="code" href="/api-reference/sdk/list">
  Complete Portkey SDK documentation
</Card>
