---
title: "Anyscale"
description: Use Anyscale's serverless endpoints for Llama, Mistral, and other open-source models through Portkey.
---

## Quick Start

Get started with Anyscale in under 2 minutes:

<CodeGroup>

```python Python (Portkey SDK)
from portkey_ai import Portkey

portkey = Portkey(api_key="PORTKEY_API_KEY")

response = portkey.chat.completions.create(
    model="@anyscale/mistralai/Mistral-7B-Instruct-v0.1",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```javascript JavaScript (Portkey SDK)
import Portkey from 'portkey-ai';

const portkey = new Portkey({
    apiKey: 'PORTKEY_API_KEY'
});

async function main() {
    const response = await portkey.chat.completions.create({
        model: "@anyscale/mistralai/Mistral-7B-Instruct-v0.1",
        messages: [{ role: "user", content: "Hello!" }]
    });

    console.log(response.choices[0].message.content);
}

main();
```

```python Python (OpenAI SDK)
from openai import OpenAI
from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL

client = OpenAI(
    api_key="x",
    base_url=PORTKEY_GATEWAY_URL,
    default_headers=createHeaders(
        api_key="PORTKEY_API_KEY",
        provider="@anyscale"
    )
)

response = client.chat.completions.create(
    model="mistralai/Mistral-7B-Instruct-v0.1",
    messages=[{"role": "user", "content": "Hello!"}]
)

print(response.choices[0].message.content)
```

```javascript JavaScript (OpenAI SDK)
import OpenAI from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai'

const client = new OpenAI({
    apiKey: 'x',
    baseURL: PORTKEY_GATEWAY_URL,
    defaultHeaders: createHeaders({
        apiKey: "PORTKEY_API_KEY",
        provider: "@anyscale"
    })
});

async function main() {
    const response = await client.chat.completions.create({
        model: 'mistralai/Mistral-7B-Instruct-v0.1',
        messages: [{ role: 'user', content: 'Hello!' }]
    });

    console.log(response.choices[0].message.content);
}

main();
```

```bash cURL
curl https://api.portkey.ai/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "x-portkey-api-key: $PORTKEY_API_KEY" \
    -H "x-portkey-provider: @anyscale" \
    -d '{
        "model": "mistralai/Mistral-7B-Instruct-v0.1",
        "messages": [{"role": "user", "content": "Hello!"}]
    }'
```

</CodeGroup>

## Add Provider in Model Catalog

Before making requests, add Anyscale to your Model Catalog:

1. Go to [**Model Catalog â†’ Add Provider**](https://app.portkey.ai/model-catalog/providers)
2. Select **Anyscale**
3. Enter your [Anyscale API key](https://console.anyscale.com/v2/api-keys)
4. Name your provider (e.g., `anyscale`)

<Card title="Complete Setup Guide" icon="book" href="/product/model-catalog">
  See all setup options and detailed configuration instructions
</Card>

---

## Supported Models

Anyscale provides serverless access to popular open-source models:

| Model | Description |
|-------|-------------|
| mistralai/Mistral-7B-Instruct-v0.1 | Mistral 7B instruction model |
| meta-llama/Llama-2-70b-chat-hf | Llama 2 70B chat |
| meta-llama/Llama-2-13b-chat-hf | Llama 2 13B chat |
| codellama/CodeLlama-34b-Instruct-hf | Code Llama 34B |
| mistralai/Mixtral-8x7B-Instruct-v0.1 | Mixtral 8x7B |

Check [Anyscale's documentation](https://docs.anyscale.com/) for the complete model list.

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Gateway Configs" icon="sliders" href="/product/ai-gateway">
    Add fallbacks, load balancing, and more
  </Card>
  <Card title="Observability" icon="chart-line" href="/product/observability">
    Monitor and trace your Anyscale requests
  </Card>
  <Card title="Prompt Library" icon="book" href="/product/prompt-engineering-studio">
    Manage and version your prompts
  </Card>
  <Card title="Metadata" icon="tag" href="/product/observability/metadata">
    Add custom metadata to requests
  </Card>
</CardGroup>

For complete SDK documentation:

<Card title="SDK Reference" icon="code" href="/api-reference/sdk/list">
  Complete Portkey SDK documentation
</Card>
