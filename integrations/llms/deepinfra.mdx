---
title: "Deepinfra"
description: "Integrate Deepinfra models with Portkey's AI Gateway"
---

Portkey provides a robust and secure gateway to integrate various Large Language Models (LLMs) into applications, including [Deepinfra's hosted models](https://deepinfra.com/models/text-generation).

With Portkey, take advantage of features like fast AI gateway access, observability, prompt management, and more, while securely managing API keys through [Model Catalog](/product/model-catalog).

## Quick Start

Get Deepinfra working in 3 steps:

<CodeGroup>
```python Python icon="python"
from portkey_ai import Portkey

# 1. Install: pip install portkey-ai
# 2. Add @deepinfra provider in model catalog
# 3. Use it:

portkey = Portkey(api_key="PORTKEY_API_KEY")

response = portkey.chat.completions.create(
    model="@deepinfra/nvidia/Nemotron-4-340B-Instruct",
    messages=[{"role": "user", "content": "Say this is a test"}]
)

print(response.choices[0].message.content)
```

```js Javascript icon="square-js"
import Portkey from 'portkey-ai'

// 1. Install: npm install portkey-ai
// 2. Add @deepinfra provider in model catalog
// 3. Use it:

const portkey = new Portkey({
    apiKey: "PORTKEY_API_KEY"
})

const response = await portkey.chat.completions.create({
    model: "@deepinfra/nvidia/Nemotron-4-340B-Instruct",
    messages: [{ role: "user", content: "Say this is a test" }]
})

console.log(response.choices[0].message.content)
```

```python OpenAI Py icon="openai"
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL

# 1. Install: pip install openai portkey-ai
# 2. Add @deepinfra provider in model catalog
# 3. Use it:

client = OpenAI(
    api_key="PORTKEY_API_KEY",  # Portkey API key
    base_url=PORTKEY_GATEWAY_URL
)

response = client.chat.completions.create(
    model="@deepinfra/nvidia/Nemotron-4-340B-Instruct",
    messages=[{"role": "user", "content": "Say this is a test"}]
)

print(response.choices[0].message.content)
```

```js OpenAI JS icon="openai"
import OpenAI from "openai"
import { PORTKEY_GATEWAY_URL } from "portkey-ai"

// 1. Install: npm install openai portkey-ai
// 2. Add @deepinfra provider in model catalog
// 3. Use it:

const client = new OpenAI({
    apiKey: "PORTKEY_API_KEY",  // Portkey API key
    baseURL: PORTKEY_GATEWAY_URL
})

const response = await client.chat.completions.create({
    model: "@deepinfra/nvidia/Nemotron-4-340B-Instruct",
    messages: [{ role: "user", content: "Say this is a test" }]
})

console.log(response.choices[0].message.content)
```

```sh cURL icon="square-terminal"
# 1. Add @deepinfra provider in model catalog
# 2. Use it:

curl https://api.portkey.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "x-portkey-api-key: $PORTKEY_API_KEY" \
  -d '{
    "model": "@deepinfra/nvidia/Nemotron-4-340B-Instruct",
    "messages": [
      { "role": "user", "content": "Say this is a test" }
    ]
  }'
```
</CodeGroup>

<Note>
**Tip:** You can also set `provider="@deepinfra"` in `Portkey()` and use just `model="nvidia/Nemotron-4-340B-Instruct"` in the request.
</Note>

## Add Provider in Model Catalog

1. Go to [**Model Catalog → Add Provider**](https://app.portkey.ai/model-catalog/providers)
2. Select **Deepinfra**
3. Choose existing credentials or create new by entering your [Deepinfra API key](https://deepinfra.com/dash/api_keys)
4. Name your provider (e.g., `deepinfra-prod`)

<Card title="Complete Setup Guide →" href="/product/model-catalog">
  See all setup options, code examples, and detailed instructions
</Card>

## Supported Models

Deepinfra hosts a wide range of open-source models for text generation. View the complete list:

<Card title="Deepinfra Models" icon="list" href="https://deepinfra.com/models/text-generation">
  Browse all available models on Deepinfra
</Card>

Popular models include:
- `nvidia/Nemotron-4-340B-Instruct`
- `meta-llama/Meta-Llama-3.1-405B-Instruct`
- `Qwen/Qwen2.5-72B-Instruct`

## Next Steps

<CardGroup cols={2}>
  <Card title="Add Metadata" icon="tags" href="/product/observability/metadata">
    Add metadata to your Deepinfra requests
  </Card>
  <Card title="Gateway Configs" icon="gear" href="/product/ai-gateway/configs">
    Add gateway configs to your Deepinfra requests
  </Card>
  <Card title="Tracing" icon="chart-line" href="/product/observability/traces">
    Trace your Deepinfra requests
  </Card>
  <Card title="Fallbacks" icon="arrow-rotate-left" href="/product/ai-gateway/fallbacks">
    Setup fallback from OpenAI to Deepinfra
  </Card>
</CardGroup>

For complete SDK documentation:

<Card title="SDK Reference" icon="code" href="/api-reference/sdk/list">
  Complete Portkey SDK documentation
</Card>
