---
title: "Patronus AI"
description: "Patronus excels in industry-specific guardrails for RAG workflows."
---
 It has a SOTA hallucination detection model Lynx, which is also [open source](https://www.patronus.ai/blog/lynx-state-of-the-art-open-source-hallucination-detection-model). Portkey integrates with multiple Patronus evaluators to help you enforce LLM behavior.

<Card title="List of all Patronus evaluators supported on Portkey" href="/product/guardrails/patronus-ai#list-of-patronus-guardrail-checks"/> Browse Patronus' docs for more info:

<Card title="What is Patronus AI?" href="https://docs.patronus.ai/" icon={<img src="/images/guardrails/f10c95b-main_logo.svg"  />}>
    Learn more about Patronus AI and their offerings.
</Card>

## Using Patronus with Portkey

### 1\. Add Patronus API Key to Portkey

Grab your Patronus API [key from here](https://app.patronus.ai/).

On the `Integrations` page, click on the edit button for the Patronus and add your API key.

<Frame>
  <img src="/images/guardrails/g5.png"/>
</Frame>

### 2\. Add Patronus' Guardrail Checks & Actions

Navigate to the `Guardrails` page and you will see the Guardrail Checks offered by Patronus there. Add the ones you want, set actions, and create the Guardrail!
<Frame>
  <img src="/images/guardrails/g5.png"/>
</Frame>

#### List of Patronus Guardrail Checks

| Check Name                 | Description                                                                                                                                       | Parameters                           | Supported Hooks   |
| :-------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------ | :----------------- |
| Retrieval Answer Relevance | Checks whether the answer is on-topic to the input question. Does not measure correctness.                                                        | **ON** or **OFF**                    | afterRequestHooks |
| Custom Evaluator           | Checks against custom criteria, based on Patronus evaluator profile name.                                                                         | **string**(evaluator's profile name) | afterRequestHooks |
| Is Concise                 | Check that the output is clear and concise.                                                                                                       | **ON** or **OFF**                    | afterRequestHooks |
| Is Helpful                 | Check that the output is helpful in its tone of voice.                                                                                            | **ON** or **OFF**                    | afterRequestHooks |
| Is Polite                  | Check that the output is polite in conversation.                                                                                                  | **ON** or **OFF**                    | afterRequestHooks |
| No Apologies               | Check that the output does not contain apologies.                                                                                                 | **ON** or **OFF**                    | afterRequestHooks |
| No Gender Bias             | Check whether the output contains gender stereotypes. Useful to mitigate PR risk from sexist or gendered model outputs.                           | **ON** or **OFF**                    | afterRequestHooks |
| No Racias Bias             | Check whether the output contains any racial stereotypes or not.                                                                                  | **ON** or **OFF**                    | afterRequestHooks |
| Detect Toxicity            | Checks output for abusive and hateful messages.                                                                                                   | **ON** or **OFF**                    | afterRequestHooks |
| Detect PII                 | Checks for personally identifiable information (PII) - this is information that, in conjunction with other data, can identify an individual.      | **ON** or **OFF**                    | afterRequestHooks |
| Detect PHI                 | Checks for protected health information (PHI), defined broadly as any information about an individual's health status or provision of healthcare. | **ON** or **OFF**                    | afterRequestHooks |

Your Patronus Guardrail is now ready to be added to any Portkey request you'd like!

### 3\. Add Guardrail ID to a Config and Make Your Request

<Info>

Patronus integration on Portkey currently only works on model outputs and not inputs.
</Info>

* When you save a Guardrail, you'll get an associated Guardrail ID - add this ID to the `after_request_hooks` params in your Portkey Config.
* Save this Config and pass it along with any Portkey request you're making!

Your requests are now guarded by your Patronus evaluators and you can see the Verdict and any action you take directly on Portkey logs! More detailed logs for your requests will also be available on your Patronus dashboard.

---

## Get Support

If you face any issues with the Patronus integration, just ping the @patronusai team on the [community forum](https://discord.gg/portkey-llms-in-prod-1143393887742861333).
