---
title: "OpenAI Agents SDK (TypeScript)"
description: "Add observability, reliability, and multi-provider support to OpenAI Agents."
---

Portkey enhances OpenAI Agents SDK with production features—no changes to your agent logic:

- Complete observability of agent steps, tool use, and handoffs
- Built-in reliability with fallbacks, retries, and load balancing
- Access to 1600+ LLMs through the same interface
- Cost tracking and optimization
- Guardrails for safe agent behavior

<Card title="OpenAI Agents SDK Documentation" icon="arrow-up-right-from-square" href="https://openai.github.io/openai-agents-js/">
  Learn more about OpenAI Agents SDK
</Card>

## Quick Start

The integration requires one change: set a Portkey-configured client as the default.

```typescript
import { Agent, run, setDefaultOpenAIClient, setOpenAIAPI } from '@openai/agents';
import { OpenAI } from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

// Configure Portkey as the default client
const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'YOUR_PORTKEY_API_KEY',
    defaultHeaders: createHeaders({ provider: '@openai-prod' })
});
setDefaultOpenAIClient(client);
setOpenAIAPI('chat_completions');

// Your agent code stays exactly the same
const agent = new Agent({
    name: 'Math Tutor',
    instructions: 'You provide help with math problems. Explain your reasoning at each step.',
    model: 'gpt-4o'
});

const result = await run(agent, 'What is the derivative of x^2?');
console.log(result.finalOutput);
```

All agent interactions are now logged in your [Portkey dashboard](https://app.portkey.ai/logs).

## Setup

<Steps>
<Step title="Install packages">
```bash
npm install @openai/agents portkey-ai openai
```
</Step>

<Step title="Add provider in Model Catalog">
Go to [Model Catalog → Add Provider](https://app.portkey.ai/model-catalog). Select your provider (OpenAI, Anthropic, etc.), enter API keys, and name it (e.g., `openai-prod`).

Your provider slug is `@openai-prod`.
</Step>

<Step title="Get Portkey API Key">
Create an API key at [app.portkey.ai/api-keys](https://app.portkey.ai/api-keys).

**Pro tip:** Attach a default [config](https://app.portkey.ai/configs) for fallbacks, caching, and guardrails—applies automatically without code changes.
</Step>

<Step title="Set the default client">
```typescript
import { setDefaultOpenAIClient, setOpenAIAPI } from '@openai/agents';
import { OpenAI } from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'YOUR_PORTKEY_API_KEY',
    defaultHeaders: createHeaders({ provider: '@openai-prod' })
});
setDefaultOpenAIClient(client);
setOpenAIAPI('chat_completions');
```

All agents now route through Portkey.
</Step>
</Steps>

## Production Features

### Observability

All agent interactions are automatically logged:

<Frame>
  <img src="/images/product/product-11-1.webp"/>
</Frame>

Add trace IDs to group related requests:

```typescript
const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'YOUR_PORTKEY_API_KEY',
    defaultHeaders: createHeaders({
        provider: '@openai-prod',
        traceId: 'agent-session-123'
    })
});
```

Add metadata for filtering and analytics:

```typescript
defaultHeaders: createHeaders({
    provider: '@openai-prod',
    traceId: 'homework-tutor',
    metadata: {
        agent_type: 'tutor',
        _user: 'user_123',
        environment: 'production'
    }
})
```

<Frame>
  <img src="/images/metadata.png" alt="Analytics with metadata filters" />
</Frame>

### Reliability

Enable fallbacks, retries, and load balancing via [Configs](https://app.portkey.ai/configs). Attach to your API key or pass inline:

```typescript
const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'YOUR_PORTKEY_API_KEY',
    defaultHeaders: createHeaders({
        config: {
            strategy: { mode: 'fallback' },
            targets: [
                { override_params: { model: '@openai-prod/gpt-4o' } },
                { override_params: { model: '@anthropic-prod/claude-sonnet-4' } }
            ]
        }
    })
});
```

If GPT-4o fails, requests automatically retry with Claude.

<CardGroup cols="2">
  <Card title="Automatic Retries" icon="rotate" href="../../product/ai-gateway/automatic-retries">
    Handles temporary failures automatically
  </Card>
  <Card title="Request Timeouts" icon="clock" href="../../product/ai-gateway/request-timeouts">
    Prevent agents from hanging
  </Card>
  <Card title="Conditional Routing" icon="route" href="../../product/ai-gateway/conditional-routing">
    Route based on request attributes
  </Card>
  <Card title="Load Balancing" icon="scale-balanced" href="../../product/ai-gateway/load-balancing">
    Distribute across multiple keys
  </Card>
</CardGroup>

### Guardrails

Add input/output validation:

```typescript
defaultHeaders: createHeaders({
    provider: '@openai-prod',
    config: {
        input_guardrails: ['guardrail-id-xxx'],
        output_guardrails: ['guardrail-id-yyy']
    }
})
```

Guardrails can:
- Detect and redact PII
- Filter harmful content
- Validate response formats
- Apply custom business rules

<Card title="Guardrails Guide" icon="shield-check" href="/product/guardrails">
  PII detection, content filtering, and custom rules
</Card>

### Caching

Reduce costs with response caching:

<CodeGroup>

```typescript Simple Cache
defaultHeaders: createHeaders({
    provider: '@openai-prod',
    config: { cache: { mode: 'simple' } }
})
```

```typescript Semantic Cache
defaultHeaders: createHeaders({
    provider: '@openai-prod',
    config: { cache: { mode: 'semantic' } }
})
```

</CodeGroup>

## Switching Providers

Use any of 1600+ models by changing the provider:

```typescript
// OpenAI
createHeaders({ provider: '@openai-prod' })
// Model: gpt-4o, gpt-4o-mini, o1, etc.

// Anthropic
createHeaders({ provider: '@anthropic-prod' })
// Model: claude-sonnet-4-20250514, claude-3-5-haiku-20241022, etc.

// Google
createHeaders({ provider: '@google-prod' })
// Model: gemini-2.0-flash, gemini-1.5-pro, etc.
```

Agent code stays the same—just update the model name to match the provider.

<Card title="Supported Providers" icon="server" href="/integrations/llms">
  See all 1600+ supported models
</Card>

## Handoffs and Multi-Agent

Portkey works seamlessly with OpenAI Agents' handoff system:

```typescript
import { Agent, run, setDefaultOpenAIClient, setOpenAIAPI } from '@openai/agents';
import { OpenAI } from 'openai';
import { PORTKEY_GATEWAY_URL, createHeaders } from 'portkey-ai';

const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'YOUR_PORTKEY_API_KEY',
    defaultHeaders: createHeaders({
        provider: '@openai-prod',
        traceId: 'homework-session'
    })
});
setDefaultOpenAIClient(client);
setOpenAIAPI('chat_completions');

// Define specialist agents
const mathTutor = new Agent({
    name: 'Math Tutor',
    handoffDescription: 'Specialist for math questions',
    instructions: 'Help with math problems. Show your work.',
    model: 'gpt-4o'
});

const historyTutor = new Agent({
    name: 'History Tutor',
    handoffDescription: 'Specialist for history questions',
    instructions: 'Help with history questions. Provide context.',
    model: 'gpt-4o'
});

// Triage agent with handoffs
const triage = new Agent({
    name: 'Triage',
    instructions: 'Route to the appropriate tutor based on the question.',
    handoffs: [mathTutor, historyTutor],
    model: 'gpt-4o'
});

const result = await run(triage, 'What caused World War I?');
console.log(result.finalOutput);
```

All handoffs are tracked in the same trace on your Portkey dashboard.

## Tools

Portkey provides full observability for tool usage:

```typescript
import { Agent, run, tool } from '@openai/agents';
import { z } from 'zod';

const getWeather = tool({
    name: 'get_weather',
    description: 'Get weather for a city',
    parameters: z.object({ city: z.string() }),
    async execute({ city }) {
        return `72°F and sunny in ${city}`;
    }
});

const agent = new Agent({
    name: 'Assistant',
    instructions: 'You can check the weather.',
    tools: [getWeather],
    model: 'gpt-4o'
});

const result = await run(agent, "What's the weather in Tokyo?");
```

Tool calls, parameters, and responses are all logged.

## Prompt Templates

Use Portkey's prompt management for versioned prompts:

```typescript
import { Portkey } from 'portkey-ai';

const portkey = new Portkey({ apiKey: 'YOUR_PORTKEY_API_KEY' });

const promptData = await portkey.prompts.render({
    promptId: 'YOUR_PROMPT_ID',
    variables: { subject: 'calculus' }
});

const agent = new Agent({
    name: 'Tutor',
    instructions: promptData.data.messages[0].content,
    model: 'gpt-4o'
});
```

<Card title="Prompt Engineering Studio" icon="wand-magic-sparkles" href="/product/prompt-library">
  Prompt versioning and collaboration
</Card>

## Enterprise Governance

Set up centralized control for OpenAI Agents across your organization.

<Steps>
<Step title="Add Provider with Budget">
Go to [Model Catalog](https://app.portkey.ai/model-catalog) → Add Provider. Set budget limits and rate limits per provider.
</Step>

<Step title="Create Config">
Go to [Configs](https://app.portkey.ai/configs):

```json
{
  "override_params": { "model": "@openai-prod/gpt-4o" }
}
```

Add fallbacks, guardrails, or routing as needed.
</Step>

<Step title="Create Team API Keys">
Go to [API Keys](https://app.portkey.ai/api-keys). Create keys per team, attach configs, and set permissions.
</Step>

<Step title="Distribute to Teams">
Teams use their Portkey API key—no raw provider keys needed:

```typescript
const client = new OpenAI({
    baseURL: PORTKEY_GATEWAY_URL,
    apiKey: 'TEAM_PORTKEY_API_KEY'  // Config attached to key
});
setDefaultOpenAIClient(client);
setOpenAIAPI('chat_completions');
```
</Step>
</Steps>

Benefits:
- Rotate provider keys without code changes
- Per-team budgets and rate limits
- Centralized usage analytics
- Instant access revocation

<Card title="Enterprise Features" icon="building" href="/product/enterprise-offering">
  Governance, security, and compliance
</Card>

## FAQ

<AccordionGroup>
  <Accordion title="Can I use Portkey with existing OpenAI Agents apps?">
    Yes. Set the default client once—agent and tool code stays unchanged.
  </Accordion>

  <Accordion title="Does Portkey work with all OpenAI Agents features?">
    Yes. Handoffs, tools, guardrails, memory, streaming—all work.
  </Accordion>

  <Accordion title="How do I track multi-agent workflows?">
    Use a consistent `traceId` across the workflow to see all agent interactions in one trace.
  </Accordion>

  <Accordion title="Can I use my own API keys?">
    Yes. Portkey stores your provider keys securely. Rotate keys without code changes.
  </Accordion>

  <Accordion title="Does Portkey support streaming?">
    Yes. Streaming responses work normally, and Portkey logs the complete interaction.
  </Accordion>
</AccordionGroup>

## Resources

<CardGroup cols="2">
  <Card title="OpenAI Agents Docs" icon="book" href="https://openai.github.io/openai-agents-js/">
    Official documentation
  </Card>
  <Card title="Book a Demo" icon="calendar" href="https://portkey.sh/openai-agents">
    Get implementation guidance
  </Card>
</CardGroup>
