{provider_slug}/{model_name}
<CodeGroup>
```python Python icon="python"
from portkey_ai import Portkey

# 1. Install: pip install portkey-ai
# 2. Add {provider_slug} provider in model catalog
# 3. Use it:

portkey = Portkey(api_key="PORTKEY_API_KEY")

response = portkey.chat.completions.create(
    model="@{provider_slug}/{model_name}",
    messages=[{"role": "user", "content": "What is Portkey's AI Gateway?"}],
    max_tokens=250
)

print(response.choices[0].message.content)
```

```js Javascript icon="square-js"
import Portkey from 'portkey-ai'

// 1. Install: npm install portkey-ai
// 2. Add {provider_slug} provider in model catalog
// 3. Use it:

const portkey = new Portkey({
    apiKey: "PORTKEY_API_KEY"
})

const response = await portkey.chat.completions.create({
    model: "{provider_slug}/{model_name}",
    messages: [{ role: "user", content: "What is Portkey's AI Gateway?" }],
    max_tokens: 250
})

console.log(response.choices[0].message.content)
```

```python OpenAI Py icon="openai"
from openai import OpenAI
from portkey_ai import PORTKEY_GATEWAY_URL

# 1. Install: pip install openai portkey-ai
# 2. Add {provider_slug} provider in model catalog
# 3. Use it:

client = OpenAI(
    api_key="PORTKEY_API_KEY",  # Portkey API key
    base_url=PORTKEY_GATEWAY_URL
)

response = client.chat.completions.create(
    model="{provider_slug}/{model_name}",
    messages=[{"role": "user", "content": "What is Portkey's AI Gateway?"}],
    max_tokens=250
)

print(response.choices[0].message.content)
```

```js OpenAI JS icon="openai"
import OpenAI from "openai"
import { PORTKEY_GATEWAY_URL } from "portkey-ai"

// 1. Install: npm install openai portkey-ai
// 2. Add {provider_slug} provider in model catalog
// 3. Use it:

const client = new OpenAI({
    apiKey: "PORTKEY_API_KEY",  // Portkey API key
    baseURL: PORTKEY_GATEWAY_URL
})

const response = await client.chat.completions.create({
    model: "{provider_slug}/{model_name}",
    messages: [{ role: "user", content: "What is Portkey's AI Gateway?" }],
    max_tokens: 250
})

console.log(response.choices[0].message.content)
```

```sh cURL icon="square-terminal"
# 1. Add {provider_slug} provider in model catalog
# 2. Use it:

# /chat/completions endpoint (OpenAI-compatible)
curl https://api.portkey.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "x-portkey-api-key: $PORTKEY_API_KEY" \
  -d '{
    "model": "{provider_slug}/{model_name}",
    "messages": [
      { "role": "user", "content": "What is Portkey's AI Gateway?" }
    ],
    "max_tokens": 250
  }'

# /messages endpoint (Anthropic native) - also supported
curl https://api.portkey.ai/v1/messages \
  -H "Content-Type: application/json" \
  -H "x-portkey-api-key: $PORTKEY_API_KEY" \
  -d '{
    "model": "{provider_slug}/{model_name}",
    "max_tokens": 250,
    "messages": [
      { "role": "user", "content": "What is Portkey's AI Gateway?" }
    ]
  }'
```

```python Anthropic Py
import anthropic

# 1. Install: pip install anthropic portkey-ai
# 2. Add {provider_slug} provider in model catalog
# 3. Use it:

client = anthropic.Anthropic(
    api_key="PORTKEY_API_KEY",
    base_url="https://api.portkey.ai"
)

message = client.messages.create(
    model="{provider_slug}/{model_name}",
    max_tokens=250,
    messages=[
        {"role": "user", "content": "What is Portkey's AI Gateway?"}
    ],
)

print(message.content)
```

```typescript Anthropic TS
import Anthropic from '@anthropic-ai/sdk'

// 1. Install: npm install @anthropic-ai/sdk portkey-ai
// 2. Add {provider_slug} provider in model catalog
// 3. Use it:

const anthropic = new Anthropic({
    apiKey: "PORTKEY_API_KEY",
    baseURL: "https://api.portkey.ai"
})

const msg = await anthropic.messages.create({
    model: "{provider_slug}/{model_name}",
    max_tokens: 250,
    messages: [{ role: "user", content: "What is Portkey's AI Gateway?" }],
})

console.log(msg)
```
</CodeGroup>