---
title: "Python"
description: "Official Portkey Python SDK to help take your AI apps to production"
---

The official Python SDK makes it easy to integrate Portkey into any Python application. Enjoy unified access to 250+ LLMs, advanced observability, routing, governance, and enterprise features with just a few lines of code.


<CardGroup cols={3}>
<Card horizontal icon="badge-check">Official</Card>
<Card horizontal icon="python" href="https://pypi.org/project/portkey-ai"> ![](https://img.shields.io/pypi/v/portkey-ai.svg) </Card>
<Card horizontal icon="github" href="https://github.com/Portkey-AI/portkey-python-sdk"> Github Repo </Card>
</CardGroup>

## Installation

Install the Portkey SDK from PyPI:

```bash
pip install portkey-ai
```

## API Key Setup

1. [Create a Portkey API key](https://app.portkey.ai) in your dashboard.
2. Store your API key securely as an environment variable:

<CodeGroup>
```sh macOS/Linux
export PORTKEY_API_KEY="your_api_key_here"
```
```sh Windows(PowerShell)
setx PORTKEY_API_KEY "your_api_key_here"
```
</CodeGroup>

<Info>The SDK automatically detects your API key from the environment.</Info>

## Quickstart

Here’s a minimal example to get you started:

```python
from portkey_ai import Portkey

client = Portkey(
    api_key="your_api_key_here",  # Or use the env var PORTKEY_API_KEY
    virtual_key="your_virtual_key_here"  # Or use config="cf-***"
)

response = client.chat.completions.create(
    messages=[{"role": "user", "content": "Hello, world!"}],
    model="gpt-4o"  # Example provider/model
)
```

<Info> You can use either a Virtual Key or a Config object to select your AI provider. Find more info on different authentication mechanisms [here](/api-reference/inference-api/headers#provider-authentication).</Info>

## Authentication & Configuration

The SDK requires:
- **Portkey API Key**: Your Portkey API key (env var `PORTKEY_API_KEY` recommended)
- **Provider Authentication**:
  - **Virtual Key**: The [Virtual Key](/product/ai-gateway/virtual-keys#using-virtual-keys) of your chosen AI provider
  - **Config**: The [Config object](/api-reference/inference-api/config-object) or config slug for advanced routing
  - **Provider Slug + Auth Headers**: Useful if you do not want to save your API keys to Portkey and make direct requests.

```python
# With Virtual Key
portkey = Portkey(api_key="...", virtual_key="...")

# With Config
portkey = Portkey(api_key="...", config="cf-***")

# With Provider Slug + Auth Headers
portkey = Portkey(api_key="...", provider="openai", Authorization = "Bearer OPENAI_API_KEY")
```

## Async Usage

Portkey supports **Async** usage - just use `AsyncPortkey` client instead of `Portkey` with `await`:


```py Python
import asyncio
from portkey_ai import AsyncPortkey

portkey = AsyncPortkey(
    api_key="PORTKEY_API_KEY",
    virtual_key="VIRTUAL_KEY"
)

async def main():
    chat_completion = await portkey.chat.completions.create(
        messages=[{'role': 'user', 'content': 'Say this is a test'}],
        model='gpt-4'
    )

    print(chat_completion)

asyncio.run(main())
```

## Using a Custom httpx Client

If you need to customize HTTP networking—for example, to disable SSL verification due to VPNs like Zscaler or to use custom proxies—you can pass your own `httpx.Client` to the Portkey SDK.

<Warning>Disabling SSL certificate verification is insecure and should only be used for debugging or in trusted internal environments. Never use this in production.</Warning>

**Example: Disable SSL Verification**
```python
import httpx
from portkey_ai import Portkey

# Create an httpx client with SSL verification disabled
custom_client = httpx.Client(verify=False)

portkey = Portkey(
    api_key="your_api_key_here",
    virtual_key="your_virtual_key_here",
    http_client=custom_client
)

response = portkey.chat.completions.create(
    messages=[{"role": "user", "content": "Hello!"}],
    model="gpt-4o"
)
print(response)
```

- You can use any `httpx.Client` options (e.g., for proxies, timeouts, custom headers).
- For async usage, pass an `httpx.AsyncClient` to `AsyncPortkey`.
- See [OpenAI Python SDK: Configuring the HTTP client](https://github.com/openai/openai-python#configuring-the-http-client) for more examples and best practices.

## Adding Trace ID or Metadata

You can choose to override the configuration in individual requests as well and send trace id or metadata along with each request.

```python
completion = portkey.with_options(
    trace_id = "TRACE_ID",
    metadata = {"_user": "USER_IDENTIFIER"}
).chat.completions.create(
    messages = [{ "role": 'user', "content": 'Say this is a test' }],
    model = 'gpt-4o'
)
```

## Parameters

<Card title="List of All Headers" icon="list" href="/api-reference/inference-api/headers#list-of-all-headers">
  View the complete list of headers that can be used with Portkey API requests, including authentication, configuration, and custom headers.
</Card>

Here's how you can use these headers with the Python SDK:

```python
portkey = Portkey(
    api_key="PORTKEY_API_KEY",
    virtual_key="VIRTUAL_KEY",
    # Add any other headers from the reference
)

# Or at runtime
completion = portkey.with_options(
    trace_id="your_trace_id",
    metadata={"_user": "user_id"},
    # Add any other headers as needed
).chat.completions.create(
    messages=[{"role": "user", "content": "Hello!"}],
    model="gpt-4o"
)
```

---

## Changelog

<Card title="View Changelog" icon="code-branch" href="https://github.com/Portkey-AI/portkey-python-sdk/tags">
  Stay updated with the latest features, improvements, and bug fixes in the Portkey Python SDK by checking the release tags on GitHub.
</Card>


## Troubleshooting & Support

- Having trouble? [Email support](mailto:support@portkey.ai) or [book a demo](https://portkey.sh/demo-15) with our team.
- [View the SDK on GitHub](https://github.com/Portkey-AI/portkey-python-sdk)
- [Report issues or request features](https://github.com/Portkey-AI/portkey-python-sdk/issues)

## FAQs

<AccordionGroup>
<Accordion title="Can I use this SDK with OpenAI-compatible code?">
Yes! Portkey’s Python SDK is OpenAI-compatible. You can also use any OpenAI-compatible library by pointing it to the Portkey API endpoint and using your Portkey API key.
</Accordion>
<Accordion title="How do I fix CERTIFICATE_VERIFY_FAILED or SSL errors?">
If you are behind a VPN (like Zscaler) or a corporate proxy and see SSL/certificate errors, you can pass a custom `httpx.Client` to the Portkey SDK with SSL verification disabled. See the docs above for an example. **Warning:** Disabling SSL verification is insecure—only use this as a last resort or for debugging.
</Accordion>
<Accordion title="Where can I find more examples?">
Check out our integration docs [here](/integrations/ecosystem).
</Accordion>
</AccordionGroup>