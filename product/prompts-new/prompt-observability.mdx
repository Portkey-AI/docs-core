---
title: "Prompt Observability"
---
Portkey's Prompt Observability provides comprehensive insights into how your prompts are performing in production. This feature allows you to track usage, monitor performance metrics, and analyze trends to continuously improve your prompts based on real-world usage.

<Info>
This feature is available on all Portkey [plans](https://portkey.ai/pricing).
</Info>

## Overview

Prompt Observability gives you visibility into your prompt usage and performance through analytics dashboards, detailed logs, and template history. By monitoring these metrics, you can identify which prompts are performing well and which need optimization, helping you make data-driven decisions about your AI applications.

## Accessing Prompt Observability

You can access observability data in several ways:

1. **From the Prompt Template page**: View history and performance metrics for a specific prompt
2. **From the Analytics dashboard**: Filter analytics by prompt ID
3. **From the Logs section**: Filter logs by prompt ID to see detailed usage information

## Prompt Analytics

The Analytics dashboard provides high-level metrics for your prompts, showing important information like costs, token usage, latency, request volume, and user engagement. You can easily filter your prompts using `prompt-id` in the analytics dashboard.

<Frame>
    <img src="/images/product/dashboard.png"/>
</Frame>
The dashboard enables you to understand trends in your prompt usage over time and identify potential opportunities for optimization. For more details on using the analytics dashboard and available filters, refer to Portkey's [Analytics documentation](/product/observability/analytics).

## Prompt Logs

The Logs section on portkey's dashboard provides detailed information about each individual prompt call, giving you visibility into exactly how your prompts are being used in real-time. You can easily filter your prompts using `prompt-id` in the logs view.

<Frame>
    <img src="/images/product/product-2.avif"/>
</Frame>
Each log entry shows the timestamp, model used, request path, user, tokens consumed, cost, and status. This granular data helps you understand exactly how your prompts are performing in production and identify any issues that need attention.

For information on filtering and searching logs, refer to Portkey's [Logs documentation](/product/observability/logs).

<Note>
**Render Calls**: Note that `prompts.render` API calls are not logged in the observability features. Only `prompts.completions` calls are tracked.
</Note>


## Prompt Template History

Each prompt template includes a "Recent" tab that shows the history of calls made using that specific template:

<Frame>
    <img src="/images/product/product-2.avif"/>
</Frame>

This chronological view makes it easy to see how your template is being used and how it's performing over time. You can quickly access detailed information about each call directly from this history view.

The template history is particularly useful when you're iterating on a prompt design, as it allows you to see the immediate impact of your changes.

## Leveraging Observability Data

Prompt observability data can help you:

- Identify which prompts are consuming the most tokens and driving costs
- Discover performance bottlenecks that may be impacting user experience
- Understand which prompts are most frequently used in your applications
- Track the impact of prompt changes on performance and cost metrics

By regularly reviewing this data, you can make informed decisions about prompt optimization, model selection, and resource allocation.

## Next Steps

Now that you understand how to monitor your prompts, explore these related features:

- [Prompt Versioning](/product/prompts-new/prompt-versioning) - Track changes to your prompts over time
- [Prompt API](/product/prompts-new/prompt-api) - Integrate optimized prompts into your applications
- [Prompt Playground](/product/prompts-new/prompt-playground) - Test and refine your prompts based on observability insights
