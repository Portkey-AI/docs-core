---
title: "Enterprise Components"
---

Portkey's Enterprise Components provide the core infrastructure needed for production deployments. Each component handles a specific function - analytics, logging, or caching - with multiple implementation options to match your requirements.

---

## Analytics Store

Portkey leverages Clickhouse as the primary Analytics Store for the Control Panel, offering powerful capabilities for handling large-scale analytical workloads.

<CardGroup cols={3}>
  <Card title="Clickhouse" icon="columns-3" href="https://github.com/Portkey-AI/helm-chart/tree/main/helm/enterprise#analytics-store"></Card>
</CardGroup>

---

## Log Store

Portkey provides flexible options for storing and managing logs in your enterprise deployment. Choose from various storage solutions including MongoDB for document-based storage, AWS S3 for cloud-native object storage, or Wasabi for cost-effective cloud storage. Each option offers different benefits in terms of scalability, cost, and integration capabilities.

<CardGroup cols={3}>
  <Card title="MongoDB" icon="leaf" href="/integrations/libraries/mongodb" />
  <Card title="AWS S3" icon="cubes" href="https://github.com/Portkey-AI/helm-chart/tree/main/helm/enterprise#log-storage" />
  <Card title="Wasabi" href="https://github.com/Portkey-AI/helm-chart/tree/main/helm/enterprise#log-storage" icon="trees" />
</CardGroup>

---

## Cache Store

Portkey supports robust caching solutions to optimize performance and reduce latency in your enterprise deployment. Choose between Redis for in-memory caching or AWS ElastiCache for a fully managed caching service.

<CardGroup cols={3}>
  <Card title="Redis" icon="r" href="https://github.com/Portkey-AI/helm-chart/tree/main/helm/enterprise#cache-store" />
  <Card title="AWS Elastic Cache" icon="aws" href="https://github.com/Portkey-AI/helm-chart/tree/main/helm/enterprise#cache-store" />
</CardGroup>


## Semantic Cache Store

Portkey supports semantic caching capabilities that allow for intelligent caching based on the semantic meaning of requests rather than exact matches. For this functionality, Portkey requires a vector database to efficiently store and retrieve embeddings. Both Milvus and Pinecone are supported vector databases for Portkey's semantic cache implementation.

### Milvus Requirements

To set up Milvus as your semantic cache store, you need:
- A Milvus deployment with a collection configured with 1536 dimensions
- This specific dimension size is required as Portkey uses OpenAI's text-embedding-small model to create embeddings

### Pinecone Requirements

Pinecone can also be configured as your semantic cache store, requiring:
- A Pinecone index with 1536 dimensions to store the embeddings
- The same dimension size requirement applies, as Portkey utilizes OpenAI's text-embedding-small model
